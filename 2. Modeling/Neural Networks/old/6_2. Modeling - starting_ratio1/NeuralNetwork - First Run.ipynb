{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b><h1>NeuralNetwork (First Run)</h1></b></center> ho incasinato l'output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, r2_score, recall_score, auc, roc_auc_score, roc_curve\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score\n",
    "import itertools\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.read_csv(\"../Data/X_train.csv\", index_col=0)\n",
    "df_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train = pd.read_csv(\"../Data/y_train.csv\", index_col=0)\n",
    "df_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30777, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_val = pd.read_csv(\"../Data/X_val.csv\", index_col=0)\n",
    "df_X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30777, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_val = pd.read_csv(\"../Data/y_val.csv\", index_col=0)\n",
    "df_y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding the best number of layers (between 1 and 2) and the best number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AUC based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  1 Best_I:  1 Best_Score:  0.5490419265376707 Actual_Score:  0.5490419265376707\n",
      "I:  2 Best_I:  1 Best_Score:  0.5490419265376707 Actual_Score:  0.47603588123598295\n",
      "I:  3 Best_I:  3 Best_Score:  0.5535501101713859 Actual_Score:  0.5535501101713859\n",
      "I:  4 Best_I:  4 Best_Score:  0.5564517812883052 Actual_Score:  0.5564517812883052\n",
      "I:  5 Best_I:  4 Best_Score:  0.5564517812883052 Actual_Score:  0.5562190334886622\n",
      "I:  6 Best_I:  4 Best_Score:  0.5564517812883052 Actual_Score:  0.5374275656913777\n",
      "I:  7 Best_I:  7 Best_Score:  0.5640744252541803 Actual_Score:  0.5640744252541803\n",
      "I:  8 Best_I:  8 Best_Score:  0.5670476402198023 Actual_Score:  0.5670476402198023\n",
      "I:  9 Best_I:  9 Best_Score:  0.5868870872257691 Actual_Score:  0.5868870872257691\n",
      "I:  10 Best_I:  9 Best_Score:  0.5868870872257691 Actual_Score:  0.5533661841397419\n",
      "I:  11 Best_I:  9 Best_Score:  0.5868870872257691 Actual_Score:  0.5657457264064968\n",
      "I:  12 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.6015612525884748\n",
      "I:  13 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.5648343867371828\n",
      "I:  14 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.5535891061747561\n",
      "I:  15 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.5486141987211768\n",
      "I:  16 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.5548259242973963\n",
      "I:  17 Best_I:  12 Best_Score:  0.6015612525884748 Actual_Score:  0.5396472673320347\n",
      "I:  18 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.6022398444581459\n",
      "I:  19 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5017422308907302\n",
      "I:  20 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.55887813104131\n",
      "I:  21 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.4851753776164169\n",
      "I:  22 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5847926640841281\n",
      "I:  23 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5588732181589956\n",
      "I:  24 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5662843011302086\n",
      "I:  25 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5821025539618712\n",
      "I:  26 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.504455063093691\n",
      "I:  27 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5570229038573495\n",
      "I:  28 Best_I:  18 Best_Score:  0.6022398444581459 Actual_Score:  0.5210771862940409\n",
      "I:  29 Best_I:  29 Best_Score:  0.6114020629192838 Actual_Score:  0.6114020629192838\n",
      "I:  30 Best_I:  29 Best_Score:  0.6114020629192838 Actual_Score:  0.5690281459027791\n",
      "I:  31 Best_I:  31 Best_Score:  0.6253878106476899 Actual_Score:  0.6253878106476899\n",
      "Best_I:  31 Best_Score:  0.6253878106476899\n"
     ]
    }
   ],
   "source": [
    "best_score_sl = actual_score = 0\n",
    "best_i_sl = 0\n",
    "for i in range(1,32,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(i,), max_iter=200000,verbose=False)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_sl:\n",
    "        best_score_sl = actual_score\n",
    "        best_i_sl = i\n",
    "    print(\"I: \", i, \"Best_I: \",best_i_sl,\"Best_Score: \", best_score_sl,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_I: \",best_i_sl,\"Best_Score: \", best_score_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,J:  1 - 1\n",
      "I,J:  1 - 2\n",
      "I,J:  1 - 3\n",
      "I,J:  1 - 4\n",
      "I,J:  1 - 5\n",
      "I,J:  1 - 6\n",
      "I,J:  1 - 7\n",
      "I,J:  1 - 8\n",
      "I,J:  1 - 9\n",
      "I,J:  1 - 10\n",
      "I,J:  1 - 11\n",
      "I,J:  1 - 12\n",
      "I,J:  1 - 13\n",
      "I,J:  1 - 14\n",
      "I,J:  1 - 15\n",
      "I,J:  1 - 16\n",
      "I,J:  1 - 17\n",
      "I,J:  1 - 18\n",
      "I,J:  1 - 19\n",
      "I,J:  1 - 20\n",
      "I,J:  1 - 21\n",
      "I,J:  1 - 22\n",
      "I,J:  1 - 23\n",
      "I,J:  1 - 24\n",
      "I,J:  1 - 25\n",
      "I,J:  1 - 26\n",
      "I,J:  1 - 27\n",
      "I,J:  1 - 28\n",
      "I,J:  1 - 29\n",
      "I,J:  1 - 30\n",
      "I,J:  1 - 31\n",
      "Best_I:  1 Best_J:  15 Best_Score:  0.5880250335918328 Actual_Score:  0.5483086788522524\n",
      "I,J:  2 - 1\n",
      "I,J:  2 - 2\n",
      "I,J:  2 - 3\n",
      "I,J:  2 - 4\n",
      "I,J:  2 - 5\n",
      "I,J:  2 - 6\n",
      "I,J:  2 - 7\n",
      "I,J:  2 - 8\n",
      "I,J:  2 - 9\n",
      "I,J:  2 - 10\n",
      "I,J:  2 - 11\n",
      "I,J:  2 - 12\n",
      "I,J:  2 - 13\n",
      "I,J:  2 - 14\n",
      "I,J:  2 - 15\n",
      "I,J:  2 - 16\n",
      "I,J:  2 - 17\n",
      "I,J:  2 - 18\n",
      "I,J:  2 - 19\n",
      "I,J:  2 - 20\n",
      "I,J:  2 - 21\n",
      "I,J:  2 - 22\n",
      "I,J:  2 - 23\n",
      "I,J:  2 - 24\n",
      "I,J:  2 - 25\n",
      "I,J:  2 - 26\n",
      "I,J:  2 - 27\n",
      "I,J:  2 - 28\n",
      "I,J:  2 - 29\n",
      "I,J:  2 - 30\n",
      "I,J:  2 - 31\n",
      "Best_I:  2 Best_J:  28 Best_Score:  0.61178434657437 Actual_Score:  0.5247320636807805\n",
      "I,J:  3 - 1\n",
      "I,J:  3 - 2\n",
      "I,J:  3 - 3\n",
      "I,J:  3 - 4\n",
      "I,J:  3 - 5\n",
      "I,J:  3 - 6\n",
      "I,J:  3 - 7\n",
      "I,J:  3 - 8\n",
      "I,J:  3 - 9\n",
      "I,J:  3 - 10\n",
      "I,J:  3 - 11\n",
      "I,J:  3 - 12\n",
      "I,J:  3 - 13\n",
      "I,J:  3 - 14\n",
      "I,J:  3 - 15\n",
      "I,J:  3 - 16\n",
      "I,J:  3 - 17\n",
      "I,J:  3 - 18\n",
      "I,J:  3 - 19\n",
      "I,J:  3 - 20\n",
      "I,J:  3 - 21\n",
      "I,J:  3 - 22\n",
      "I,J:  3 - 23\n",
      "I,J:  3 - 24\n",
      "I,J:  3 - 25\n",
      "I,J:  3 - 26\n",
      "I,J:  3 - 27\n",
      "I,J:  3 - 28\n",
      "I,J:  3 - 29\n",
      "I,J:  3 - 30\n",
      "I,J:  3 - 31\n",
      "Best_I:  2 Best_J:  28 Best_Score:  0.61178434657437 Actual_Score:  0.5296160828115444\n",
      "I,J:  4 - 1\n",
      "I,J:  4 - 2\n",
      "I,J:  4 - 3\n",
      "I,J:  4 - 4\n",
      "I,J:  4 - 5\n",
      "I,J:  4 - 6\n",
      "I,J:  4 - 7\n",
      "I,J:  4 - 8\n",
      "I,J:  4 - 9\n",
      "I,J:  4 - 10\n",
      "I,J:  4 - 11\n",
      "I,J:  4 - 12\n",
      "I,J:  4 - 13\n",
      "I,J:  4 - 14\n",
      "I,J:  4 - 15\n",
      "I,J:  4 - 16\n",
      "I,J:  4 - 17\n",
      "I,J:  4 - 18\n",
      "I,J:  4 - 19\n",
      "I,J:  4 - 20\n",
      "I,J:  4 - 21\n",
      "I,J:  4 - 22\n",
      "I,J:  4 - 23\n",
      "I,J:  4 - 24\n",
      "I,J:  4 - 25\n",
      "I,J:  4 - 26\n",
      "I,J:  4 - 27\n",
      "I,J:  4 - 28\n",
      "I,J:  4 - 29\n",
      "I,J:  4 - 30\n",
      "I,J:  4 - 31\n",
      "Best_I:  4 Best_J:  20 Best_Score:  0.6127316116956075 Actual_Score:  0.5190982158867876\n",
      "I,J:  5 - 1\n",
      "I,J:  5 - 2\n",
      "I,J:  5 - 3\n",
      "I,J:  5 - 4\n",
      "I,J:  5 - 5\n",
      "I,J:  5 - 6\n",
      "I,J:  5 - 7\n",
      "I,J:  5 - 8\n",
      "I,J:  5 - 9\n",
      "I,J:  5 - 10\n",
      "I,J:  5 - 11\n",
      "I,J:  5 - 12\n",
      "I,J:  5 - 13\n",
      "I,J:  5 - 14\n",
      "I,J:  5 - 15\n",
      "I,J:  5 - 16\n",
      "I,J:  5 - 17\n",
      "I,J:  5 - 18\n",
      "I,J:  5 - 19\n",
      "I,J:  5 - 20\n",
      "I,J:  5 - 21\n",
      "I,J:  5 - 22\n",
      "I,J:  5 - 23\n",
      "I,J:  5 - 24\n",
      "I,J:  5 - 25\n",
      "I,J:  5 - 26\n",
      "I,J:  5 - 27\n",
      "I,J:  5 - 28\n",
      "I,J:  5 - 29\n",
      "I,J:  5 - 30\n",
      "I,J:  5 - 31\n",
      "Best_I:  5 Best_J:  26 Best_Score:  0.6156968432274689 Actual_Score:  0.4855610388780942\n",
      "I,J:  6 - 1\n",
      "I,J:  6 - 2\n",
      "I,J:  6 - 3\n",
      "I,J:  6 - 4\n",
      "I,J:  6 - 5\n",
      "I,J:  6 - 6\n",
      "I,J:  6 - 7\n",
      "I,J:  6 - 8\n",
      "I,J:  6 - 9\n",
      "I,J:  6 - 10\n",
      "I,J:  6 - 11\n",
      "I,J:  6 - 12\n",
      "I,J:  6 - 13\n",
      "I,J:  6 - 14\n",
      "I,J:  6 - 15\n",
      "I,J:  6 - 16\n",
      "I,J:  6 - 17\n",
      "I,J:  6 - 18\n",
      "I,J:  6 - 19\n",
      "I,J:  6 - 20\n",
      "I,J:  6 - 21\n",
      "I,J:  6 - 22\n",
      "I,J:  6 - 23\n",
      "I,J:  6 - 24\n",
      "I,J:  6 - 25\n",
      "I,J:  6 - 26\n",
      "I,J:  6 - 27\n",
      "I,J:  6 - 28\n",
      "I,J:  6 - 29\n",
      "I,J:  6 - 30\n",
      "I,J:  6 - 31\n",
      "Best_I:  5 Best_J:  26 Best_Score:  0.6156968432274689 Actual_Score:  0.5160860049177951\n",
      "I,J:  7 - 1\n",
      "I,J:  7 - 2\n",
      "I,J:  7 - 3\n",
      "I,J:  7 - 4\n",
      "I,J:  7 - 5\n",
      "I,J:  7 - 6\n",
      "I,J:  7 - 7\n",
      "I,J:  7 - 8\n",
      "I,J:  7 - 9\n",
      "I,J:  7 - 10\n",
      "I,J:  7 - 11\n",
      "I,J:  7 - 12\n",
      "I,J:  7 - 13\n",
      "I,J:  7 - 14\n",
      "I,J:  7 - 15\n",
      "I,J:  7 - 16\n",
      "I,J:  7 - 17\n",
      "I,J:  7 - 18\n",
      "I,J:  7 - 19\n",
      "I,J:  7 - 20\n",
      "I,J:  7 - 21\n",
      "I,J:  7 - 22\n",
      "I,J:  7 - 23\n",
      "I,J:  7 - 24\n",
      "I,J:  7 - 25\n",
      "I,J:  7 - 26\n",
      "I,J:  7 - 27\n",
      "I,J:  7 - 28\n",
      "I,J:  7 - 29\n",
      "I,J:  7 - 30\n",
      "I,J:  7 - 31\n",
      "Best_I:  5 Best_J:  26 Best_Score:  0.6156968432274689 Actual_Score:  0.5474799370168486\n",
      "I,J:  8 - 1\n",
      "I,J:  8 - 2\n",
      "I,J:  8 - 3\n",
      "I,J:  8 - 4\n",
      "I,J:  8 - 5\n",
      "I,J:  8 - 6\n",
      "I,J:  8 - 7\n",
      "I,J:  8 - 8\n",
      "I,J:  8 - 9\n",
      "I,J:  8 - 10\n",
      "I,J:  8 - 11\n",
      "I,J:  8 - 12\n",
      "I,J:  8 - 13\n",
      "I,J:  8 - 14\n",
      "I,J:  8 - 15\n",
      "I,J:  8 - 16\n",
      "I,J:  8 - 17\n",
      "I,J:  8 - 18\n",
      "I,J:  8 - 19\n",
      "I,J:  8 - 20\n",
      "I,J:  8 - 21\n",
      "I,J:  8 - 22\n",
      "I,J:  8 - 23\n",
      "I,J:  8 - 24\n",
      "I,J:  8 - 25\n",
      "I,J:  8 - 26\n",
      "I,J:  8 - 27\n",
      "I,J:  8 - 28\n",
      "I,J:  8 - 29\n",
      "I,J:  8 - 30\n",
      "I,J:  8 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5856063602174442\n",
      "I,J:  9 - 1\n",
      "I,J:  9 - 2\n",
      "I,J:  9 - 3\n",
      "I,J:  9 - 4\n",
      "I,J:  9 - 5\n",
      "I,J:  9 - 6\n",
      "I,J:  9 - 7\n",
      "I,J:  9 - 8\n",
      "I,J:  9 - 9\n",
      "I,J:  9 - 10\n",
      "I,J:  9 - 11\n",
      "I,J:  9 - 12\n",
      "I,J:  9 - 13\n",
      "I,J:  9 - 14\n",
      "I,J:  9 - 15\n",
      "I,J:  9 - 16\n",
      "I,J:  9 - 17\n",
      "I,J:  9 - 18\n",
      "I,J:  9 - 19\n",
      "I,J:  9 - 20\n",
      "I,J:  9 - 21\n",
      "I,J:  9 - 22\n",
      "I,J:  9 - 23\n",
      "I,J:  9 - 24\n",
      "I,J:  9 - 25\n",
      "I,J:  9 - 26\n",
      "I,J:  9 - 27\n",
      "I,J:  9 - 28\n",
      "I,J:  9 - 29\n",
      "I,J:  9 - 30\n",
      "I,J:  9 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5956424576202489\n",
      "I,J:  10 - 1\n",
      "I,J:  10 - 2\n",
      "I,J:  10 - 3\n",
      "I,J:  10 - 4\n",
      "I,J:  10 - 5\n",
      "I,J:  10 - 6\n",
      "I,J:  10 - 7\n",
      "I,J:  10 - 8\n",
      "I,J:  10 - 9\n",
      "I,J:  10 - 10\n",
      "I,J:  10 - 11\n",
      "I,J:  10 - 12\n",
      "I,J:  10 - 13\n",
      "I,J:  10 - 14\n",
      "I,J:  10 - 15\n",
      "I,J:  10 - 16\n",
      "I,J:  10 - 17\n",
      "I,J:  10 - 18\n",
      "I,J:  10 - 19\n",
      "I,J:  10 - 20\n",
      "I,J:  10 - 21\n",
      "I,J:  10 - 22\n",
      "I,J:  10 - 23\n",
      "I,J:  10 - 24\n",
      "I,J:  10 - 25\n",
      "I,J:  10 - 26\n",
      "I,J:  10 - 27\n",
      "I,J:  10 - 28\n",
      "I,J:  10 - 29\n",
      "I,J:  10 - 30\n",
      "I,J:  10 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.49700651939483115\n",
      "I,J:  11 - 1\n",
      "I,J:  11 - 2\n",
      "I,J:  11 - 3\n",
      "I,J:  11 - 4\n",
      "I,J:  11 - 5\n",
      "I,J:  11 - 6\n",
      "I,J:  11 - 7\n",
      "I,J:  11 - 8\n",
      "I,J:  11 - 9\n",
      "I,J:  11 - 10\n",
      "I,J:  11 - 11\n",
      "I,J:  11 - 12\n",
      "I,J:  11 - 13\n",
      "I,J:  11 - 14\n",
      "I,J:  11 - 15\n",
      "I,J:  11 - 16\n",
      "I,J:  11 - 17\n",
      "I,J:  11 - 18\n",
      "I,J:  11 - 19\n",
      "I,J:  11 - 20\n",
      "I,J:  11 - 21\n",
      "I,J:  11 - 22\n",
      "I,J:  11 - 23\n",
      "I,J:  11 - 24\n",
      "I,J:  11 - 25\n",
      "I,J:  11 - 26\n",
      "I,J:  11 - 27\n",
      "I,J:  11 - 28\n",
      "I,J:  11 - 29\n",
      "I,J:  11 - 30\n",
      "I,J:  11 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5632297165512549\n",
      "I,J:  12 - 1\n",
      "I,J:  12 - 2\n",
      "I,J:  12 - 3\n",
      "I,J:  12 - 4\n",
      "I,J:  12 - 5\n",
      "I,J:  12 - 6\n",
      "I,J:  12 - 7\n",
      "I,J:  12 - 8\n",
      "I,J:  12 - 9\n",
      "I,J:  12 - 10\n",
      "I,J:  12 - 11\n",
      "I,J:  12 - 12\n",
      "I,J:  12 - 13\n",
      "I,J:  12 - 14\n",
      "I,J:  12 - 15\n",
      "I,J:  12 - 16\n",
      "I,J:  12 - 17\n",
      "I,J:  12 - 18\n",
      "I,J:  12 - 19\n",
      "I,J:  12 - 20\n",
      "I,J:  12 - 21\n",
      "I,J:  12 - 22\n",
      "I,J:  12 - 23\n",
      "I,J:  12 - 24\n",
      "I,J:  12 - 25\n",
      "I,J:  12 - 26\n",
      "I,J:  12 - 27\n",
      "I,J:  12 - 28\n",
      "I,J:  12 - 29\n",
      "I,J:  12 - 30\n",
      "I,J:  12 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5344770728064594\n",
      "I,J:  13 - 1\n",
      "I,J:  13 - 2\n",
      "I,J:  13 - 3\n",
      "I,J:  13 - 4\n",
      "I,J:  13 - 5\n",
      "I,J:  13 - 6\n",
      "I,J:  13 - 7\n",
      "I,J:  13 - 8\n",
      "I,J:  13 - 9\n",
      "I,J:  13 - 10\n",
      "I,J:  13 - 11\n",
      "I,J:  13 - 12\n",
      "I,J:  13 - 13\n",
      "I,J:  13 - 14\n",
      "I,J:  13 - 15\n",
      "I,J:  13 - 16\n",
      "I,J:  13 - 17\n",
      "I,J:  13 - 18\n",
      "I,J:  13 - 19\n",
      "I,J:  13 - 20\n",
      "I,J:  13 - 21\n",
      "I,J:  13 - 22\n",
      "I,J:  13 - 23\n",
      "I,J:  13 - 24\n",
      "I,J:  13 - 25\n",
      "I,J:  13 - 26\n",
      "I,J:  13 - 27\n",
      "I,J:  13 - 28\n",
      "I,J:  13 - 29\n",
      "I,J:  13 - 30\n",
      "I,J:  13 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.6009803042548016\n",
      "I,J:  14 - 1\n",
      "I,J:  14 - 2\n",
      "I,J:  14 - 3\n",
      "I,J:  14 - 4\n",
      "I,J:  14 - 5\n",
      "I,J:  14 - 6\n",
      "I,J:  14 - 7\n",
      "I,J:  14 - 8\n",
      "I,J:  14 - 9\n",
      "I,J:  14 - 10\n",
      "I,J:  14 - 11\n",
      "I,J:  14 - 12\n",
      "I,J:  14 - 13\n",
      "I,J:  14 - 14\n",
      "I,J:  14 - 15\n",
      "I,J:  14 - 16\n",
      "I,J:  14 - 17\n",
      "I,J:  14 - 18\n",
      "I,J:  14 - 19\n",
      "I,J:  14 - 20\n",
      "I,J:  14 - 21\n",
      "I,J:  14 - 22\n",
      "I,J:  14 - 23\n",
      "I,J:  14 - 24\n",
      "I,J:  14 - 25\n",
      "I,J:  14 - 26\n",
      "I,J:  14 - 27\n",
      "I,J:  14 - 28\n",
      "I,J:  14 - 29\n",
      "I,J:  14 - 30\n",
      "I,J:  14 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.6100789623009975\n",
      "I,J:  15 - 1\n",
      "I,J:  15 - 2\n",
      "I,J:  15 - 3\n",
      "I,J:  15 - 4\n",
      "I,J:  15 - 5\n",
      "I,J:  15 - 6\n",
      "I,J:  15 - 7\n",
      "I,J:  15 - 8\n",
      "I,J:  15 - 9\n",
      "I,J:  15 - 10\n",
      "I,J:  15 - 11\n",
      "I,J:  15 - 12\n",
      "I,J:  15 - 13\n",
      "I,J:  15 - 14\n",
      "I,J:  15 - 15\n",
      "I,J:  15 - 16\n",
      "I,J:  15 - 17\n",
      "I,J:  15 - 18\n",
      "I,J:  15 - 19\n",
      "I,J:  15 - 20\n",
      "I,J:  15 - 21\n",
      "I,J:  15 - 22\n",
      "I,J:  15 - 23\n",
      "I,J:  15 - 24\n",
      "I,J:  15 - 25\n",
      "I,J:  15 - 26\n",
      "I,J:  15 - 27\n",
      "I,J:  15 - 28\n",
      "I,J:  15 - 29\n",
      "I,J:  15 - 30\n",
      "I,J:  15 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5688816805987821\n",
      "I,J:  16 - 1\n",
      "I,J:  16 - 2\n",
      "I,J:  16 - 3\n",
      "I,J:  16 - 4\n",
      "I,J:  16 - 5\n",
      "I,J:  16 - 6\n",
      "I,J:  16 - 7\n",
      "I,J:  16 - 8\n",
      "I,J:  16 - 9\n",
      "I,J:  16 - 10\n",
      "I,J:  16 - 11\n",
      "I,J:  16 - 12\n",
      "I,J:  16 - 13\n",
      "I,J:  16 - 14\n",
      "I,J:  16 - 15\n",
      "I,J:  16 - 16\n",
      "I,J:  16 - 17\n",
      "I,J:  16 - 18\n",
      "I,J:  16 - 19\n",
      "I,J:  16 - 20\n",
      "I,J:  16 - 21\n",
      "I,J:  16 - 22\n",
      "I,J:  16 - 23\n",
      "I,J:  16 - 24\n",
      "I,J:  16 - 25\n",
      "I,J:  16 - 26\n",
      "I,J:  16 - 27\n",
      "I,J:  16 - 28\n",
      "I,J:  16 - 29\n",
      "I,J:  16 - 30\n",
      "I,J:  16 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5587218399726843\n",
      "I,J:  17 - 1\n",
      "I,J:  17 - 2\n",
      "I,J:  17 - 3\n",
      "I,J:  17 - 4\n",
      "I,J:  17 - 5\n",
      "I,J:  17 - 6\n",
      "I,J:  17 - 7\n",
      "I,J:  17 - 8\n",
      "I,J:  17 - 9\n",
      "I,J:  17 - 10\n",
      "I,J:  17 - 11\n",
      "I,J:  17 - 12\n",
      "I,J:  17 - 13\n",
      "I,J:  17 - 14\n",
      "I,J:  17 - 15\n",
      "I,J:  17 - 16\n",
      "I,J:  17 - 17\n",
      "I,J:  17 - 18\n",
      "I,J:  17 - 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,J:  17 - 20\n",
      "I,J:  17 - 21\n",
      "I,J:  17 - 22\n",
      "I,J:  17 - 23\n",
      "I,J:  17 - 24\n",
      "I,J:  17 - 25\n",
      "I,J:  17 - 26\n",
      "I,J:  17 - 27\n",
      "I,J:  17 - 28\n",
      "I,J:  17 - 29\n",
      "I,J:  17 - 30\n",
      "I,J:  17 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.6096119314259887\n",
      "I,J:  18 - 1\n",
      "I,J:  18 - 2\n",
      "I,J:  18 - 3\n",
      "I,J:  18 - 4\n",
      "I,J:  18 - 5\n",
      "I,J:  18 - 6\n",
      "I,J:  18 - 7\n",
      "I,J:  18 - 8\n",
      "I,J:  18 - 9\n",
      "I,J:  18 - 10\n",
      "I,J:  18 - 11\n",
      "I,J:  18 - 12\n",
      "I,J:  18 - 13\n",
      "I,J:  18 - 14\n",
      "I,J:  18 - 15\n",
      "I,J:  18 - 16\n",
      "I,J:  18 - 17\n",
      "I,J:  18 - 18\n",
      "I,J:  18 - 19\n",
      "I,J:  18 - 20\n",
      "I,J:  18 - 21\n",
      "I,J:  18 - 22\n",
      "I,J:  18 - 23\n",
      "I,J:  18 - 24\n",
      "I,J:  18 - 25\n",
      "I,J:  18 - 26\n",
      "I,J:  18 - 27\n",
      "I,J:  18 - 28\n",
      "I,J:  18 - 29\n",
      "I,J:  18 - 30\n",
      "I,J:  18 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.61417999081291\n",
      "I,J:  19 - 1\n",
      "I,J:  19 - 2\n",
      "I,J:  19 - 3\n",
      "I,J:  19 - 4\n",
      "I,J:  19 - 5\n",
      "I,J:  19 - 6\n",
      "I,J:  19 - 7\n",
      "I,J:  19 - 8\n",
      "I,J:  19 - 9\n",
      "I,J:  19 - 10\n",
      "I,J:  19 - 11\n",
      "I,J:  19 - 12\n",
      "I,J:  19 - 13\n",
      "I,J:  19 - 14\n",
      "I,J:  19 - 15\n",
      "I,J:  19 - 16\n",
      "I,J:  19 - 17\n",
      "I,J:  19 - 18\n",
      "I,J:  19 - 19\n",
      "I,J:  19 - 20\n",
      "I,J:  19 - 21\n",
      "I,J:  19 - 22\n",
      "I,J:  19 - 23\n",
      "I,J:  19 - 24\n",
      "I,J:  19 - 25\n",
      "I,J:  19 - 26\n",
      "I,J:  19 - 27\n",
      "I,J:  19 - 28\n",
      "I,J:  19 - 29\n",
      "I,J:  19 - 30\n",
      "I,J:  19 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5593988965666321\n",
      "I,J:  20 - 1\n",
      "I,J:  20 - 2\n",
      "I,J:  20 - 3\n",
      "I,J:  20 - 4\n",
      "I,J:  20 - 5\n",
      "I,J:  20 - 6\n",
      "I,J:  20 - 7\n",
      "I,J:  20 - 8\n",
      "I,J:  20 - 9\n",
      "I,J:  20 - 10\n",
      "I,J:  20 - 11\n",
      "I,J:  20 - 12\n",
      "I,J:  20 - 13\n",
      "I,J:  20 - 14\n",
      "I,J:  20 - 15\n",
      "I,J:  20 - 16\n",
      "I,J:  20 - 17\n",
      "I,J:  20 - 18\n",
      "I,J:  20 - 19\n",
      "I,J:  20 - 20\n",
      "I,J:  20 - 21\n",
      "I,J:  20 - 22\n",
      "I,J:  20 - 23\n",
      "I,J:  20 - 24\n",
      "I,J:  20 - 25\n",
      "I,J:  20 - 26\n",
      "I,J:  20 - 27\n",
      "I,J:  20 - 28\n",
      "I,J:  20 - 29\n",
      "I,J:  20 - 30\n",
      "I,J:  20 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5785597517029277\n",
      "I,J:  21 - 1\n",
      "I,J:  21 - 2\n",
      "I,J:  21 - 3\n",
      "I,J:  21 - 4\n",
      "I,J:  21 - 5\n",
      "I,J:  21 - 6\n",
      "I,J:  21 - 7\n",
      "I,J:  21 - 8\n",
      "I,J:  21 - 9\n",
      "I,J:  21 - 10\n",
      "I,J:  21 - 11\n",
      "I,J:  21 - 12\n",
      "I,J:  21 - 13\n",
      "I,J:  21 - 14\n",
      "I,J:  21 - 15\n",
      "I,J:  21 - 16\n",
      "I,J:  21 - 17\n",
      "I,J:  21 - 18\n",
      "I,J:  21 - 19\n",
      "I,J:  21 - 20\n",
      "I,J:  21 - 21\n",
      "I,J:  21 - 22\n",
      "I,J:  21 - 23\n",
      "I,J:  21 - 24\n",
      "I,J:  21 - 25\n",
      "I,J:  21 - 26\n",
      "I,J:  21 - 27\n",
      "I,J:  21 - 28\n",
      "I,J:  21 - 29\n",
      "I,J:  21 - 30\n",
      "I,J:  21 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5778599730282761\n",
      "I,J:  22 - 1\n",
      "I,J:  22 - 2\n",
      "I,J:  22 - 3\n",
      "I,J:  22 - 4\n",
      "I,J:  22 - 5\n",
      "I,J:  22 - 6\n",
      "I,J:  22 - 7\n",
      "I,J:  22 - 8\n",
      "I,J:  22 - 9\n",
      "I,J:  22 - 10\n",
      "I,J:  22 - 11\n",
      "I,J:  22 - 12\n",
      "I,J:  22 - 13\n",
      "I,J:  22 - 14\n",
      "I,J:  22 - 15\n",
      "I,J:  22 - 16\n",
      "I,J:  22 - 17\n",
      "I,J:  22 - 18\n",
      "I,J:  22 - 19\n",
      "I,J:  22 - 20\n",
      "I,J:  22 - 21\n",
      "I,J:  22 - 22\n",
      "I,J:  22 - 23\n",
      "I,J:  22 - 24\n",
      "I,J:  22 - 25\n",
      "I,J:  22 - 26\n",
      "I,J:  22 - 27\n",
      "I,J:  22 - 28\n",
      "I,J:  22 - 29\n",
      "I,J:  22 - 30\n",
      "I,J:  22 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.582607045564527\n",
      "I,J:  23 - 1\n",
      "I,J:  23 - 2\n",
      "I,J:  23 - 3\n",
      "I,J:  23 - 4\n",
      "I,J:  23 - 5\n",
      "I,J:  23 - 6\n",
      "I,J:  23 - 7\n",
      "I,J:  23 - 8\n",
      "I,J:  23 - 9\n",
      "I,J:  23 - 10\n",
      "I,J:  23 - 11\n",
      "I,J:  23 - 12\n",
      "I,J:  23 - 13\n",
      "I,J:  23 - 14\n",
      "I,J:  23 - 15\n",
      "I,J:  23 - 16\n",
      "I,J:  23 - 17\n",
      "I,J:  23 - 18\n",
      "I,J:  23 - 19\n",
      "I,J:  23 - 20\n",
      "I,J:  23 - 21\n",
      "I,J:  23 - 22\n",
      "I,J:  23 - 23\n",
      "I,J:  23 - 24\n",
      "I,J:  23 - 25\n",
      "I,J:  23 - 26\n",
      "I,J:  23 - 27\n",
      "I,J:  23 - 28\n",
      "I,J:  23 - 29\n",
      "I,J:  23 - 30\n",
      "I,J:  23 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5762863154119575\n",
      "I,J:  24 - 1\n",
      "I,J:  24 - 2\n",
      "I,J:  24 - 3\n",
      "I,J:  24 - 4\n",
      "I,J:  24 - 5\n",
      "I,J:  24 - 6\n",
      "I,J:  24 - 7\n",
      "I,J:  24 - 8\n",
      "I,J:  24 - 9\n",
      "I,J:  24 - 10\n",
      "I,J:  24 - 11\n",
      "I,J:  24 - 12\n",
      "I,J:  24 - 13\n",
      "I,J:  24 - 14\n",
      "I,J:  24 - 15\n",
      "I,J:  24 - 16\n",
      "I,J:  24 - 17\n",
      "I,J:  24 - 18\n",
      "I,J:  24 - 19\n",
      "I,J:  24 - 20\n",
      "I,J:  24 - 21\n",
      "I,J:  24 - 22\n",
      "I,J:  24 - 23\n",
      "I,J:  24 - 24\n",
      "I,J:  24 - 25\n",
      "I,J:  24 - 26\n",
      "I,J:  24 - 27\n",
      "I,J:  24 - 28\n",
      "I,J:  24 - 29\n",
      "I,J:  24 - 30\n",
      "I,J:  24 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5320522583291778\n",
      "I,J:  25 - 1\n",
      "I,J:  25 - 2\n",
      "I,J:  25 - 3\n",
      "I,J:  25 - 4\n",
      "I,J:  25 - 5\n",
      "I,J:  25 - 6\n",
      "I,J:  25 - 7\n",
      "I,J:  25 - 8\n",
      "I,J:  25 - 9\n",
      "I,J:  25 - 10\n",
      "I,J:  25 - 11\n",
      "I,J:  25 - 12\n",
      "I,J:  25 - 13\n",
      "I,J:  25 - 14\n",
      "I,J:  25 - 15\n",
      "I,J:  25 - 16\n",
      "I,J:  25 - 17\n",
      "I,J:  25 - 18\n",
      "I,J:  25 - 19\n",
      "I,J:  25 - 20\n",
      "I,J:  25 - 21\n",
      "I,J:  25 - 22\n",
      "I,J:  25 - 23\n",
      "I,J:  25 - 24\n",
      "I,J:  25 - 25\n",
      "I,J:  25 - 26\n",
      "I,J:  25 - 27\n",
      "I,J:  25 - 28\n",
      "I,J:  25 - 29\n",
      "I,J:  25 - 30\n",
      "I,J:  25 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5374389267317297\n",
      "I,J:  26 - 1\n",
      "I,J:  26 - 2\n",
      "I,J:  26 - 3\n",
      "I,J:  26 - 4\n",
      "I,J:  26 - 5\n",
      "I,J:  26 - 6\n",
      "I,J:  26 - 7\n",
      "I,J:  26 - 8\n",
      "I,J:  26 - 9\n",
      "I,J:  26 - 10\n",
      "I,J:  26 - 11\n",
      "I,J:  26 - 12\n",
      "I,J:  26 - 13\n",
      "I,J:  26 - 14\n",
      "I,J:  26 - 15\n",
      "I,J:  26 - 16\n",
      "I,J:  26 - 17\n",
      "I,J:  26 - 18\n",
      "I,J:  26 - 19\n",
      "I,J:  26 - 20\n",
      "I,J:  26 - 21\n",
      "I,J:  26 - 22\n",
      "I,J:  26 - 23\n",
      "I,J:  26 - 24\n",
      "I,J:  26 - 25\n",
      "I,J:  26 - 26\n",
      "I,J:  26 - 27\n",
      "I,J:  26 - 28\n",
      "I,J:  26 - 29\n",
      "I,J:  26 - 30\n",
      "I,J:  26 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5746702841856774\n",
      "I,J:  27 - 1\n",
      "I,J:  27 - 2\n",
      "I,J:  27 - 3\n",
      "I,J:  27 - 4\n",
      "I,J:  27 - 5\n",
      "I,J:  27 - 6\n",
      "I,J:  27 - 7\n",
      "I,J:  27 - 8\n",
      "I,J:  27 - 9\n",
      "I,J:  27 - 10\n",
      "I,J:  27 - 11\n",
      "I,J:  27 - 12\n",
      "I,J:  27 - 13\n",
      "I,J:  27 - 14\n",
      "I,J:  27 - 15\n",
      "I,J:  27 - 16\n",
      "I,J:  27 - 17\n",
      "I,J:  27 - 18\n",
      "I,J:  27 - 19\n",
      "I,J:  27 - 20\n",
      "I,J:  27 - 21\n",
      "I,J:  27 - 22\n",
      "I,J:  27 - 23\n",
      "I,J:  27 - 24\n",
      "I,J:  27 - 25\n",
      "I,J:  27 - 26\n",
      "I,J:  27 - 27\n",
      "I,J:  27 - 28\n",
      "I,J:  27 - 29\n",
      "I,J:  27 - 30\n",
      "I,J:  27 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5285631907205478\n",
      "I,J:  28 - 1\n",
      "I,J:  28 - 2\n",
      "I,J:  28 - 3\n",
      "I,J:  28 - 4\n",
      "I,J:  28 - 5\n",
      "I,J:  28 - 6\n",
      "I,J:  28 - 7\n",
      "I,J:  28 - 8\n",
      "I,J:  28 - 9\n",
      "I,J:  28 - 10\n",
      "I,J:  28 - 11\n",
      "I,J:  28 - 12\n",
      "I,J:  28 - 13\n",
      "I,J:  28 - 14\n",
      "I,J:  28 - 15\n",
      "I,J:  28 - 16\n",
      "I,J:  28 - 17\n",
      "I,J:  28 - 18\n",
      "I,J:  28 - 19\n",
      "I,J:  28 - 20\n",
      "I,J:  28 - 21\n",
      "I,J:  28 - 22\n",
      "I,J:  28 - 23\n",
      "I,J:  28 - 24\n",
      "I,J:  28 - 25\n",
      "I,J:  28 - 26\n",
      "I,J:  28 - 27\n",
      "I,J:  28 - 28\n",
      "I,J:  28 - 29\n",
      "I,J:  28 - 30\n",
      "I,J:  28 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5677262320894735\n",
      "I,J:  29 - 1\n",
      "I,J:  29 - 2\n",
      "I,J:  29 - 3\n",
      "I,J:  29 - 4\n",
      "I,J:  29 - 5\n",
      "I,J:  29 - 6\n",
      "I,J:  29 - 7\n",
      "I,J:  29 - 8\n",
      "I,J:  29 - 9\n",
      "I,J:  29 - 10\n",
      "I,J:  29 - 11\n",
      "I,J:  29 - 12\n",
      "I,J:  29 - 13\n",
      "I,J:  29 - 14\n",
      "I,J:  29 - 15\n",
      "I,J:  29 - 16\n",
      "I,J:  29 - 17\n",
      "I,J:  29 - 18\n",
      "I,J:  29 - 19\n",
      "I,J:  29 - 20\n",
      "I,J:  29 - 21\n",
      "I,J:  29 - 22\n",
      "I,J:  29 - 23\n",
      "I,J:  29 - 24\n",
      "I,J:  29 - 25\n",
      "I,J:  29 - 26\n",
      "I,J:  29 - 27\n",
      "I,J:  29 - 28\n",
      "I,J:  29 - 29\n",
      "I,J:  29 - 30\n",
      "I,J:  29 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5623444765692359\n",
      "I,J:  30 - 1\n",
      "I,J:  30 - 2\n",
      "I,J:  30 - 3\n",
      "I,J:  30 - 4\n",
      "I,J:  30 - 5\n",
      "I,J:  30 - 6\n",
      "I,J:  30 - 7\n",
      "I,J:  30 - 8\n",
      "I,J:  30 - 9\n",
      "I,J:  30 - 10\n",
      "I,J:  30 - 11\n",
      "I,J:  30 - 12\n",
      "I,J:  30 - 13\n",
      "I,J:  30 - 14\n",
      "I,J:  30 - 15\n",
      "I,J:  30 - 16\n",
      "I,J:  30 - 17\n",
      "I,J:  30 - 18\n",
      "I,J:  30 - 19\n",
      "I,J:  30 - 20\n",
      "I,J:  30 - 21\n",
      "I,J:  30 - 22\n",
      "I,J:  30 - 23\n",
      "I,J:  30 - 24\n",
      "I,J:  30 - 25\n",
      "I,J:  30 - 26\n",
      "I,J:  30 - 27\n",
      "I,J:  30 - 28\n",
      "I,J:  30 - 29\n",
      "I,J:  30 - 30\n",
      "I,J:  30 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5527428621961075\n",
      "I,J:  31 - 1\n",
      "I,J:  31 - 2\n",
      "I,J:  31 - 3\n",
      "I,J:  31 - 4\n",
      "I,J:  31 - 5\n",
      "I,J:  31 - 6\n",
      "I,J:  31 - 7\n",
      "I,J:  31 - 8\n",
      "I,J:  31 - 9\n",
      "I,J:  31 - 10\n",
      "I,J:  31 - 11\n",
      "I,J:  31 - 12\n",
      "I,J:  31 - 13\n",
      "I,J:  31 - 14\n",
      "I,J:  31 - 15\n",
      "I,J:  31 - 16\n",
      "I,J:  31 - 17\n",
      "I,J:  31 - 18\n",
      "I,J:  31 - 19\n",
      "I,J:  31 - 20\n",
      "I,J:  31 - 21\n",
      "I,J:  31 - 22\n",
      "I,J:  31 - 23\n",
      "I,J:  31 - 24\n",
      "I,J:  31 - 25\n",
      "I,J:  31 - 26\n",
      "I,J:  31 - 27\n",
      "I,J:  31 - 28\n",
      "I,J:  31 - 29\n",
      "I,J:  31 - 30\n",
      "I,J:  31 - 31\n",
      "Best_I:  8 Best_J:  14 Best_Score:  0.6518783791418669 Actual_Score:  0.5286771081792121\n",
      "Best_I:  8 Best_I:  14 Best_Score:  0.6518783791418669\n"
     ]
    }
   ],
   "source": [
    "best_score_twol = actual_score = 0\n",
    "best_i_twol = best_j_twol = 0\n",
    "for i in range(1,32,1):\n",
    "    for j in range(1,32,1):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(i,j,), max_iter=200000,verbose=False)\n",
    "        mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "        predictions = mlp.predict(df_X_val.values)\n",
    "        fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "        actual_score = auc(fpr, tpr)\n",
    "        if actual_score > best_score_twol:\n",
    "            best_score_twol = actual_score\n",
    "            best_i_twol = i\n",
    "            best_j_twol = j\n",
    "        print(\"I,J: \", i,\"-\",j)\n",
    "    print(\"Best_I: \", best_i_twol,\"Best_J: \", best_j_twol,\"Best_Score: \", best_score_twol,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_I: \",best_i_twol,\"Best_I: \",best_j_twol,\"Best_Score: \", best_score_twol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Find the best random state for both single layer and two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  1 Best_Random_State:  1 Best_Score:  0.5627301378309134 Actual_Score:  0.5627301378309134\n",
      "I:  2 Best_Random_State:  1 Best_Score:  0.5627301378309134 Actual_Score:  0.5433528088176411\n",
      "I:  3 Best_Random_State:  1 Best_Score:  0.5627301378309134 Actual_Score:  0.5532848145264104\n",
      "I:  4 Best_Random_State:  4 Best_Score:  0.5656594439108509 Actual_Score:  0.5656594439108509\n",
      "I:  5 Best_Random_State:  4 Best_Score:  0.5656594439108509 Actual_Score:  0.5552214113237025\n",
      "I:  6 Best_Random_State:  4 Best_Score:  0.5656594439108509 Actual_Score:  0.5636902992682262\n",
      "I:  7 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5755165281643261\n",
      "I:  8 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5336682895554579\n",
      "I:  9 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5542498888460375\n",
      "I:  10 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5395545366783511\n",
      "I:  11 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5740893358520043\n",
      "I:  12 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5369669829744063\n",
      "I:  13 Best_Random_State:  7 Best_Score:  0.5755165281643261 Actual_Score:  0.5577503174950196\n",
      "I:  14 Best_Random_State:  14 Best_Score:  0.5875755048600688 Actual_Score:  0.5875755048600688\n",
      "I:  15 Best_Random_State:  14 Best_Score:  0.5875755048600688 Actual_Score:  0.5664243182761679\n",
      "I:  16 Best_Random_State:  14 Best_Score:  0.5875755048600688 Actual_Score:  0.5600173056279523\n",
      "I:  17 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5913851380397108\n",
      "I:  18 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5573809301560086\n",
      "I:  19 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.578450747126578\n",
      "I:  20 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5359840994563896\n",
      "I:  21 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5738516751700472\n",
      "I:  22 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5632069944705509\n",
      "I:  23 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5698255681134287\n",
      "I:  24 Best_Random_State:  17 Best_Score:  0.5913851380397108 Actual_Score:  0.5167044139791153\n",
      "I:  25 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.6333033852215587\n",
      "I:  26 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5436994740759483\n",
      "I:  27 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5410630986040045\n",
      "I:  28 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5363973956810851\n",
      "I:  29 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5578577867956462\n",
      "I:  30 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5993805469511879\n",
      "I:  31 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5437206608809289\n",
      "I:  32 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5105967800969311\n",
      "I:  33 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5850855946921218\n",
      "I:  34 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5828511544045218\n",
      "I:  35 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5472960109852049\n",
      "I:  36 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5534214540657786\n",
      "I:  37 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5727287745060711\n",
      "I:  38 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5594965401026302\n",
      "I:  39 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5531985320307644\n",
      "I:  40 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5098856403819275\n",
      "I:  41 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5622256462282573\n",
      "I:  42 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5513221180418234\n",
      "I:  43 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.551380765574451\n",
      "I:  44 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.588835045063413\n",
      "I:  45 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5560025596116858\n",
      "I:  46 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5911508549643448\n",
      "I:  47 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5725058524710569\n",
      "I:  48 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5922037470553411\n",
      "I:  49 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5538933978231018\n",
      "I:  50 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5479681546968382\n",
      "I:  51 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5420769946916306\n",
      "I:  52 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5631858076655704\n",
      "I:  53 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5899303107643709\n",
      "I:  54 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.583925233300499\n",
      "I:  55 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5335608202548312\n",
      "I:  56 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5301856701048655\n",
      "I:  57 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.554869833183081\n",
      "I:  58 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5279285077365614\n",
      "I:  59 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5609562802602845\n",
      "I:  60 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5645202693242085\n",
      "I:  61 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5932615520286518\n",
      "I:  62 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5855200777217983\n",
      "I:  63 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5674121146764989\n",
      "I:  64 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5507411697081501\n",
      "I:  65 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5419907121959847\n",
      "I:  66 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5703675204437315\n",
      "I:  67 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5459615493265667\n",
      "I:  68 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5536216540200887\n",
      "I:  69 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5624258461825675\n",
      "I:  70 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5643738040202115\n",
      "I:  71 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5799755829748976\n",
      "I:  72 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.555634707548398\n",
      "I:  73 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.593424291255315\n",
      "I:  74 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.589648741196729\n",
      "I:  75 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.567954067006802\n",
      "I:  76 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5785548388206135\n",
      "I:  77 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5721641000950644\n",
      "I:  78 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.6182321975568236\n",
      "I:  79 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5756141717003239\n",
      "I:  80 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5635601078868957\n",
      "I:  81 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.591264772423009\n",
      "I:  82 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5442039656786042\n",
      "I:  83 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5921874731326748\n",
      "I:  84 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5775784034606344\n",
      "I:  85 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.6015124308204758\n",
      "I:  86 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5612866715959252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  87 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5397660976730132\n",
      "I:  88 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5940915220846341\n",
      "I:  89 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5235898185426917\n",
      "I:  90 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5873215702554453\n",
      "I:  91 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5702210551397346\n",
      "I:  92 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5595828225982761\n",
      "I:  93 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5437645697666136\n",
      "I:  94 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.582704689100525\n",
      "I:  95 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5664243182761679\n",
      "I:  96 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5608098149562877\n",
      "I:  97 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5373575571183979\n",
      "I:  98 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5655780742975193\n",
      "I:  99 Best_Random_State:  25 Best_Score:  0.6333033852215587 Actual_Score:  0.5563231251826979\n",
      "Best_Random_State:  25 Best_Score:  0.6333033852215587\n"
     ]
    }
   ],
   "source": [
    "best_score_sl = actual_score = 0\n",
    "best_random_state_sl = 0\n",
    "for i in range(1,100,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_sl,), max_iter=200000,verbose=False, random_state=i)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_sl:\n",
    "        best_score_sl = actual_score\n",
    "        best_random_state_sl = i\n",
    "    print(\"I: \", i, \"Best_Random_State: \",best_random_state_sl,\"Best_Score: \", best_score_sl,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_Random_State: \",best_random_state_sl,\"Best_Score: \", best_score_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  1 Best_Random_State:  1 Best_Score:  0.5517664268361284 Actual_Score:  0.5517664268361284\n",
      "I:  2 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.5564321297590478\n",
      "I:  3 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.5148980085631539\n",
      "I:  4 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.508474721992272\n",
      "I:  5 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.5464546798888705\n",
      "I:  6 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.5275818424782543\n",
      "I:  7 Best_Random_State:  2 Best_Score:  0.5564321297590478 Actual_Score:  0.5544841719214036\n",
      "I:  8 Best_Random_State:  8 Best_Score:  0.5635112861188967 Actual_Score:  0.5635112861188967\n",
      "I:  9 Best_Random_State:  8 Best_Score:  0.5635112861188967 Actual_Score:  0.5146652607635109\n",
      "I:  10 Best_Random_State:  10 Best_Score:  0.5828235194415035 Actual_Score:  0.5828235194415035\n",
      "I:  11 Best_Random_State:  10 Best_Score:  0.5828235194415035 Actual_Score:  0.5808218269535461\n",
      "I:  12 Best_Random_State:  10 Best_Score:  0.5828235194415035 Actual_Score:  0.5727662352337181\n",
      "I:  13 Best_Random_State:  10 Best_Score:  0.5828235194415035 Actual_Score:  0.5763953199883073\n",
      "I:  14 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5839365943408508\n",
      "I:  15 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5608423628016203\n",
      "I:  16 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5116757718752226\n",
      "I:  17 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.539565897718703\n",
      "I:  18 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5716156996067238\n",
      "I:  19 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5505833433638014\n",
      "I:  20 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5602614144679472\n",
      "I:  21 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5512554870754348\n",
      "I:  22 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.547198367449207\n",
      "I:  23 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5540822367370601\n",
      "I:  24 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.510780706128575\n",
      "I:  25 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5119312417555694\n",
      "I:  26 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5312597490008426\n",
      "I:  27 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5577991392630186\n",
      "I:  28 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5709174562077952\n",
      "I:  29 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5541147845823928\n",
      "I:  30 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5657911705679046\n",
      "I:  31 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.4763045544875495\n",
      "I:  32 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5661590226311923\n",
      "I:  33 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5757118152363219\n",
      "I:  34 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5431575217456452\n",
      "I:  35 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5604241536946103\n",
      "I:  36 Best_Random_State:  14 Best_Score:  0.5839365943408508 Actual_Score:  0.5317154188354996\n",
      "I:  37 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.6103279840233068\n",
      "I:  38 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.6079519913140241\n",
      "I:  39 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5840001547557929\n",
      "I:  40 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5473822934808508\n",
      "I:  41 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5830789893218503\n",
      "I:  42 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5049270068510143\n",
      "I:  43 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5282539861898877\n",
      "I:  44 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5926643297723125\n",
      "I:  45 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5279398687769135\n",
      "I:  46 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5842083381438639\n",
      "I:  47 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5167483228648\n",
      "I:  48 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5298113698835402\n",
      "I:  49 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5175230229947456\n",
      "I:  50 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5886609447963979\n",
      "I:  51 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5274353771742575\n",
      "I:  52 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5732642786783364\n",
      "I:  53 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5283255300385906\n",
      "I:  54 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.574035601201691\n",
      "I:  55 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5013304699417578\n",
      "I:  56 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.536988169779387\n",
      "I:  57 Best_Random_State:  37 Best_Score:  0.6103279840233068 Actual_Score:  0.5737816665970674\n",
      "I:  58 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.6167349966715222\n",
      "I:  59 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5555533379350663\n",
      "I:  60 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5329847848034724\n",
      "I:  61 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5715407781514297\n",
      "I:  62 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5692071590521084\n",
      "I:  63 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5324201103924656\n",
      "I:  64 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5523734748570965\n",
      "I:  65 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.51882155920146\n",
      "I:  66 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5600596792379137\n",
      "I:  67 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5546696332287707\n",
      "I:  68 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5631369858975712\n",
      "I:  69 Best_Random_State:  58 Best_Score:  0.6167349966715222 Actual_Score:  0.5548259242973963\n",
      "I:  70 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.6235992144301179\n",
      "I:  71 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5589806874596221\n",
      "I:  72 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5711551168897524\n",
      "I:  73 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.511161454507938\n",
      "I:  74 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5575599433053381\n",
      "I:  75 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5772203771619753\n",
      "I:  76 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5321222669021576\n",
      "I:  77 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5453170405779515\n",
      "I:  78 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5377155834170569\n",
      "I:  79 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5801985050099118\n",
      "I:  80 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.510852249977278\n",
      "I:  81 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5828625154448737\n",
      "I:  82 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5651924130358419\n",
      "I:  83 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5771503685889956\n",
      "I:  84 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5505345215958025\n",
      "I:  85 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5803336092735567\n",
      "I:  86 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5853524256128206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  87 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.4963408238412353\n",
      "I:  88 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5457499883319046\n",
      "I:  89 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5059537992547158\n",
      "I:  90 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5784571952846156\n",
      "I:  91 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5662990397771516\n",
      "I:  92 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5234759010840274\n",
      "I:  93 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5157995224678391\n",
      "I:  94 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5498184689984844\n",
      "I:  95 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.4969902454721648\n",
      "I:  96 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5398962890543438\n",
      "I:  97 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5861483125477471\n",
      "I:  98 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5920735556740105\n",
      "I:  99 Best_Random_State:  70 Best_Score:  0.6235992144301179 Actual_Score:  0.5108685238999443\n",
      "Best_Random_State:  70 Best_Score:  0.6235992144301179\n"
     ]
    }
   ],
   "source": [
    "best_score_twol = actual_score = 0\n",
    "best_random_state_twol = 0\n",
    "for i in range(1,100,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_twol,best_j_twol), max_iter=200000,verbose=False, random_state=i)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_twol:\n",
    "        best_score_twol = actual_score\n",
    "        best_random_state_twol = i\n",
    "    print(\"I: \", i, \"Best_Random_State: \",best_random_state_twol,\"Best_Score: \", best_score_twol,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_Random_State: \",best_random_state_twol,\"Best_Score: \", best_score_twol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute metrics on the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best architecture is :  One Layers\n",
      "For the layer  1  the best number of neurons is :  31\n"
     ]
    }
   ],
   "source": [
    "if best_score_sl > best_score_twol:\n",
    "    best_architecture = \"One Layers\"\n",
    "    best_neurons = [best_i_sl]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_sl,), max_iter=200000,verbose=False, random_state=best_random_state_sl)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "else:\n",
    "    best_architecture = \"Two Layers\"\n",
    "    best_neurons = [best_i_twol, best_j_twol]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_twol,best_j_twol), max_iter=200000,verbose=False, random_state=best_random_state_twol)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "\n",
    "predictions = mlp.predict(df_X_val.values)\n",
    "print(\"The best architecture is : \", best_architecture)\n",
    "layer = 0\n",
    "for neuron in best_neurons:\n",
    "    layer += 1\n",
    "    print(\"For the layer \", layer, \" the best number of neurons is : \", neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16307 14417]\n",
      " [   14    39]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(df_y_val['Class'].values,predictions)\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Fracture       1.00      0.53      0.69     30724\n",
      "    Fracture       0.00      0.74      0.01        53\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     30777\n",
      "   macro avg       0.50      0.63      0.35     30777\n",
      "weighted avg       1.00      0.53      0.69     30777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_val['Class'].values,predictions,target_names=['Non-Fracture','Fracture']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.531110894499139\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / float(tp+tn+fp+fn)\n",
    "print(\"Accuracy : \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Recall (or Sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall :  0.7358490566037735\n"
     ]
    }
   ],
   "source": [
    "recall = tp/(tp+fn)\n",
    "print(\"Recall : \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error :  0.46888910550086105\n"
     ]
    }
   ],
   "source": [
    "classification_error = (fp + fn) / float(tp+tn+fp+fn)\n",
    "print(\"Error : \",classification_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5307577138393438\n"
     ]
    }
   ],
   "source": [
    "specificity = tn / (tn+fp)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 False Positive Rate: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46924228616065616\n",
      "0.4692422861606562\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = fp / float(tn+fp)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Precision: When a positive value is predicted, how often is the prediction correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002697841726618705\n"
     ]
    }
   ],
   "source": [
    "precision = tp / float(tp+fp)\n",
    "\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_y_val, predictions)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creation new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = pd.DataFrame(df_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>HIPX</th>\n",
       "      <th>menopause</th>\n",
       "      <th>HRT</th>\n",
       "      <th>smoking</th>\n",
       "      <th>ReumatoidArthritis</th>\n",
       "      <th>SecondaryOsteoporsis</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>VitaminD</th>\n",
       "      <th>calcium</th>\n",
       "      <th>dose_walk</th>\n",
       "      <th>dose_moderate</th>\n",
       "      <th>dose_vigorous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>-1.383228</td>\n",
       "      <td>-1.438686</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.141958</td>\n",
       "      <td>0.115530</td>\n",
       "      <td>-0.259297</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.538945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43265</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-1.957990</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>1.770734</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>1.276093</td>\n",
       "      <td>0.113305</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>0.201583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116861</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>1.145866</td>\n",
       "      <td>2.161613</td>\n",
       "      <td>1.498749</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>-0.366965</td>\n",
       "      <td>-0.493062</td>\n",
       "      <td>0.583416</td>\n",
       "      <td>-0.353813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46479</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-0.716448</td>\n",
       "      <td>-0.803047</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>2.330176</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>3.056626</td>\n",
       "      <td>-1.030506</td>\n",
       "      <td>-0.598176</td>\n",
       "      <td>-0.504194</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.168681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115581</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>-0.095676</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.737192</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>-0.874557</td>\n",
       "      <td>-0.343833</td>\n",
       "      <td>-0.593247</td>\n",
       "      <td>-0.562138</td>\n",
       "      <td>-0.508090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sex       age    weight    height      HIPX  menopause       HRT  \\\n",
       "149978 -1.029482  0.152632 -1.383228 -1.438686 -0.037838   1.436838 -0.423252   \n",
       "43265   0.971362 -1.957990  0.637841  1.770734 -0.037838  -0.695973 -0.423252   \n",
       "116861  0.971362  1.145866  2.161613  1.498749 -0.037838  -0.695973 -0.423252   \n",
       "46479   0.971362 -0.716448 -0.803047  0.845986 -0.037838  -0.695973 -0.423252   \n",
       "115581 -1.029482 -0.095676  0.274431  0.737192 -0.037838   1.436838 -0.423252   \n",
       "\n",
       "         smoking  ReumatoidArthritis  SecondaryOsteoporsis   Alcohol  \\\n",
       "149978 -0.808640            -0.08895             -0.134216 -0.612333   \n",
       "43265   0.760768            -0.08895             -0.134216  0.104979   \n",
       "116861  0.760768            -0.08895             -0.134216  0.104979   \n",
       "46479   2.330176            -0.08895             -0.134216  3.056626   \n",
       "115581 -0.808640            -0.08895             -0.134216  0.397031   \n",
       "\n",
       "        VitaminD   calcium  dose_walk  dose_moderate  dose_vigorous  \n",
       "149978 -0.141958  0.115530  -0.259297      -0.462525      -0.538945  \n",
       "43265   1.276093  0.113305  -0.637774      -0.611945       0.201583  \n",
       "116861 -0.504631 -0.366965  -0.493062       0.583416      -0.353813  \n",
       "46479  -1.030506 -0.598176  -0.504194      -0.462525      -0.168681  \n",
       "115581 -0.874557 -0.343833  -0.593247      -0.562138      -0.508090  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df['real_class'] = df_y_val\n",
    "mod_df['predicted_class'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>HIPX</th>\n",
       "      <th>menopause</th>\n",
       "      <th>HRT</th>\n",
       "      <th>smoking</th>\n",
       "      <th>ReumatoidArthritis</th>\n",
       "      <th>SecondaryOsteoporsis</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>VitaminD</th>\n",
       "      <th>calcium</th>\n",
       "      <th>dose_walk</th>\n",
       "      <th>dose_moderate</th>\n",
       "      <th>dose_vigorous</th>\n",
       "      <th>real_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>-1.383228</td>\n",
       "      <td>-1.438686</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.141958</td>\n",
       "      <td>0.115530</td>\n",
       "      <td>-0.259297</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.538945</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43265</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-1.957990</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>1.770734</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>1.276093</td>\n",
       "      <td>0.113305</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116861</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>1.145866</td>\n",
       "      <td>2.161613</td>\n",
       "      <td>1.498749</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>-0.366965</td>\n",
       "      <td>-0.493062</td>\n",
       "      <td>0.583416</td>\n",
       "      <td>-0.353813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46479</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-0.716448</td>\n",
       "      <td>-0.803047</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>2.330176</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>3.056626</td>\n",
       "      <td>-1.030506</td>\n",
       "      <td>-0.598176</td>\n",
       "      <td>-0.504194</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.168681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115581</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>-0.095676</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.737192</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>-0.874557</td>\n",
       "      <td>-0.343833</td>\n",
       "      <td>-0.593247</td>\n",
       "      <td>-0.562138</td>\n",
       "      <td>-0.508090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sex       age    weight    height      HIPX  menopause       HRT  \\\n",
       "149978 -1.029482  0.152632 -1.383228 -1.438686 -0.037838   1.436838 -0.423252   \n",
       "43265   0.971362 -1.957990  0.637841  1.770734 -0.037838  -0.695973 -0.423252   \n",
       "116861  0.971362  1.145866  2.161613  1.498749 -0.037838  -0.695973 -0.423252   \n",
       "46479   0.971362 -0.716448 -0.803047  0.845986 -0.037838  -0.695973 -0.423252   \n",
       "115581 -1.029482 -0.095676  0.274431  0.737192 -0.037838   1.436838 -0.423252   \n",
       "\n",
       "         smoking  ReumatoidArthritis  SecondaryOsteoporsis   Alcohol  \\\n",
       "149978 -0.808640            -0.08895             -0.134216 -0.612333   \n",
       "43265   0.760768            -0.08895             -0.134216  0.104979   \n",
       "116861  0.760768            -0.08895             -0.134216  0.104979   \n",
       "46479   2.330176            -0.08895             -0.134216  3.056626   \n",
       "115581 -0.808640            -0.08895             -0.134216  0.397031   \n",
       "\n",
       "        VitaminD   calcium  dose_walk  dose_moderate  dose_vigorous  \\\n",
       "149978 -0.141958  0.115530  -0.259297      -0.462525      -0.538945   \n",
       "43265   1.276093  0.113305  -0.637774      -0.611945       0.201583   \n",
       "116861 -0.504631 -0.366965  -0.493062       0.583416      -0.353813   \n",
       "46479  -1.030506 -0.598176  -0.504194      -0.462525      -0.168681   \n",
       "115581 -0.874557 -0.343833  -0.593247      -0.562138      -0.508090   \n",
       "\n",
       "        real_class  predicted_class  \n",
       "149978           0                1  \n",
       "43265            0                0  \n",
       "116861           0                0  \n",
       "46479            0                1  \n",
       "115581           0                0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_df_complete = mod_df[(mod_df['real_class'] == 0) & ( mod_df['predicted_class']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erennio/anaconda2/envs/Python36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14417, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df_complete['Class'] = mod_df['real_class']\n",
    "mod_df_complete = mod_df_complete.drop(['real_class','predicted_class'],axis=1)\n",
    "mod_df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153884, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_patients = pd.read_csv('../Data/standardized_patients.csv', index_col=0)\n",
    "std_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index in mod_df_complete.index.values:\n",
    "    feature_to_check = std_patients.loc[index].round(10) == mod_df_complete.loc[index].round(10)\n",
    "    for check in feature_to_check:\n",
    "        if not check:\n",
    "            print(index, feature_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in mod_df_complete.index.values:\n",
    "    equals = True\n",
    "    patient = std_patients.loc[index].round(10) == mod_df_complete.loc[index].round(10)\n",
    "    for feature in patient:\n",
    "        if not feature:\n",
    "            equals = False\n",
    "            print(std_patients.loc[index].round(10) == giorgiONE.loc[index].round(10), index)\n",
    "    if equals:\n",
    "        std_patients.loc[index,'Class'] = 1        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14417,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_patients.loc[mod_df_complete.index.values,'Class'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_patients.to_csv('../Data/new_std_patients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NeuralNetwork - First Run.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlp, 'NeuralNetwork - First Run.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
