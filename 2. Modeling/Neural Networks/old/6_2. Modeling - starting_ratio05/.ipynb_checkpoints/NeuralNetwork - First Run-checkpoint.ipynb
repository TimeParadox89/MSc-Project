{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b><h1>NeuralNetwork (First Run)</h1></b></center> ho incasinato l'output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, r2_score, recall_score, auc, roc_auc_score, roc_curve\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score\n",
    "import itertools\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.read_csv(\"../Data/X_train.csv\", index_col=0)\n",
    "df_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train = pd.read_csv(\"../Data/y_train.csv\", index_col=0)\n",
    "df_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30777, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_val = pd.read_csv(\"../Data/X_val.csv\", index_col=0)\n",
    "df_X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30777, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_val = pd.read_csv(\"../Data/y_val.csv\", index_col=0)\n",
    "df_y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding the best number of layers (between 1 and 2) and the best number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AUC based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  1 Best_I:  1 Best_Score:  0.5 Actual_Score:  0.5\n",
      "I:  2 Best_I:  2 Best_Score:  0.5394900550979752 Actual_Score:  0.5394900550979752\n",
      "I:  3 Best_I:  2 Best_Score:  0.5394900550979752 Actual_Score:  0.5233773363825955\n",
      "I:  4 Best_I:  4 Best_Score:  0.5488816437521647 Actual_Score:  0.5488816437521647\n",
      "I:  5 Best_I:  5 Best_Score:  0.5515260026578693 Actual_Score:  0.5515260026578693\n",
      "I:  6 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5689341870285168\n",
      "I:  7 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5601137209433716\n",
      "I:  8 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5348713316121869\n",
      "I:  9 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5374490595515029\n",
      "I:  10 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5451905338583567\n",
      "I:  11 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.5436119633597237\n",
      "I:  12 Best_I:  6 Best_Score:  0.5689341870285168 Actual_Score:  0.542874723957425\n",
      "I:  13 Best_I:  13 Best_Score:  0.5699072447819049 Actual_Score:  0.5699072447819049\n",
      "I:  14 Best_I:  14 Best_Score:  0.5746705912408221 Actual_Score:  0.5746705912408221\n",
      "I:  15 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5827863657690012\n",
      "I:  16 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5227276076965214\n",
      "I:  17 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5711391500222308\n",
      "I:  18 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5727941772518811\n",
      "I:  19 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5311200389100279\n",
      "I:  20 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5822444134386984\n",
      "I:  21 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5432229244914553\n",
      "I:  22 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5428323503474636\n",
      "I:  23 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5719642071958987\n",
      "I:  24 Best_I:  15 Best_Score:  0.5827863657690012 Actual_Score:  0.5094253647201008\n",
      "I:  25 Best_I:  25 Best_Score:  0.5832484837616958 Actual_Score:  0.5832484837616958\n",
      "I:  26 Best_I:  25 Best_Score:  0.5832484837616958 Actual_Score:  0.5461034088033938\n",
      "I:  27 Best_I:  25 Best_Score:  0.5832484837616958 Actual_Score:  0.5623186839370856\n",
      "I:  28 Best_I:  25 Best_Score:  0.5832484837616958 Actual_Score:  0.5655360077427026\n",
      "I:  29 Best_I:  29 Best_Score:  0.592552254644516 Actual_Score:  0.592552254644516\n",
      "I:  30 Best_I:  30 Best_Score:  0.594363572942792 Actual_Score:  0.594363572942792\n",
      "I:  31 Best_I:  30 Best_Score:  0.594363572942792 Actual_Score:  0.5473027661983871\n",
      "Best_I:  30 Best_Score:  0.594363572942792\n"
     ]
    }
   ],
   "source": [
    "best_score_sl = actual_score = 0\n",
    "best_i_sl = 0\n",
    "for i in range(1,32,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(i,), max_iter=200000,verbose=False)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_sl:\n",
    "        best_score_sl = actual_score\n",
    "        best_i_sl = i\n",
    "    print(\"I: \", i, \"Best_I: \",best_i_sl,\"Best_Score: \", best_score_sl,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_I: \",best_i_sl,\"Best_Score: \", best_score_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,J:  1 - 1\n",
      "I,J:  1 - 2\n",
      "I,J:  1 - 3\n",
      "I,J:  1 - 4\n",
      "I,J:  1 - 5\n",
      "I,J:  1 - 6\n",
      "I,J:  1 - 7\n",
      "I,J:  1 - 8\n",
      "I,J:  1 - 9\n",
      "I,J:  1 - 10\n",
      "I,J:  1 - 11\n",
      "I,J:  1 - 12\n",
      "I,J:  1 - 13\n",
      "I,J:  1 - 14\n",
      "I,J:  1 - 15\n",
      "I,J:  1 - 16\n",
      "I,J:  1 - 17\n",
      "I,J:  1 - 18\n",
      "I,J:  1 - 19\n",
      "I,J:  1 - 20\n",
      "I,J:  1 - 21\n",
      "I,J:  1 - 22\n",
      "I,J:  1 - 23\n",
      "I,J:  1 - 24\n",
      "I,J:  1 - 25\n",
      "I,J:  1 - 26\n",
      "I,J:  1 - 27\n",
      "I,J:  1 - 28\n",
      "I,J:  1 - 29\n",
      "I,J:  1 - 30\n",
      "I,J:  1 - 31\n",
      "Best_I:  1 Best_J:  27 Best_Score:  0.5547712684816491 Actual_Score:  0.5\n",
      "I,J:  2 - 1\n",
      "I,J:  2 - 2\n",
      "I,J:  2 - 3\n",
      "I,J:  2 - 4\n",
      "I,J:  2 - 5\n",
      "I,J:  2 - 6\n",
      "I,J:  2 - 7\n",
      "I,J:  2 - 8\n",
      "I,J:  2 - 9\n",
      "I,J:  2 - 10\n",
      "I,J:  2 - 11\n",
      "I,J:  2 - 12\n",
      "I,J:  2 - 13\n",
      "I,J:  2 - 14\n",
      "I,J:  2 - 15\n",
      "I,J:  2 - 16\n",
      "I,J:  2 - 17\n",
      "I,J:  2 - 18\n",
      "I,J:  2 - 19\n",
      "I,J:  2 - 20\n",
      "I,J:  2 - 21\n",
      "I,J:  2 - 22\n",
      "I,J:  2 - 23\n",
      "I,J:  2 - 24\n",
      "I,J:  2 - 25\n",
      "I,J:  2 - 26\n",
      "I,J:  2 - 27\n",
      "I,J:  2 - 28\n",
      "I,J:  2 - 29\n",
      "I,J:  2 - 30\n",
      "I,J:  2 - 31\n",
      "Best_I:  2 Best_J:  23 Best_Score:  0.5764186561793005 Actual_Score:  0.5121320558201689\n",
      "I,J:  3 - 1\n",
      "I,J:  3 - 2\n",
      "I,J:  3 - 3\n",
      "I,J:  3 - 4\n",
      "I,J:  3 - 5\n",
      "I,J:  3 - 6\n",
      "I,J:  3 - 7\n",
      "I,J:  3 - 8\n",
      "I,J:  3 - 9\n",
      "I,J:  3 - 10\n",
      "I,J:  3 - 11\n",
      "I,J:  3 - 12\n",
      "I,J:  3 - 13\n",
      "I,J:  3 - 14\n",
      "I,J:  3 - 15\n",
      "I,J:  3 - 16\n",
      "I,J:  3 - 17\n",
      "I,J:  3 - 18\n",
      "I,J:  3 - 19\n",
      "I,J:  3 - 20\n",
      "I,J:  3 - 21\n",
      "I,J:  3 - 22\n",
      "I,J:  3 - 23\n",
      "I,J:  3 - 24\n",
      "I,J:  3 - 25\n",
      "I,J:  3 - 26\n",
      "I,J:  3 - 27\n",
      "I,J:  3 - 28\n",
      "I,J:  3 - 29\n",
      "I,J:  3 - 30\n",
      "I,J:  3 - 31\n",
      "Best_I:  3 Best_J:  10 Best_Score:  0.5778458484916223 Actual_Score:  0.5441701896126929\n",
      "I,J:  4 - 1\n",
      "I,J:  4 - 2\n",
      "I,J:  4 - 3\n",
      "I,J:  4 - 4\n",
      "I,J:  4 - 5\n",
      "I,J:  4 - 6\n",
      "I,J:  4 - 7\n",
      "I,J:  4 - 8\n",
      "I,J:  4 - 9\n",
      "I,J:  4 - 10\n",
      "I,J:  4 - 11\n",
      "I,J:  4 - 12\n",
      "I,J:  4 - 13\n",
      "I,J:  4 - 14\n",
      "I,J:  4 - 15\n",
      "I,J:  4 - 16\n",
      "I,J:  4 - 17\n",
      "I,J:  4 - 18\n",
      "I,J:  4 - 19\n",
      "I,J:  4 - 20\n",
      "I,J:  4 - 21\n",
      "I,J:  4 - 22\n",
      "I,J:  4 - 23\n",
      "I,J:  4 - 24\n",
      "I,J:  4 - 25\n",
      "I,J:  4 - 26\n",
      "I,J:  4 - 27\n",
      "I,J:  4 - 28\n",
      "I,J:  4 - 29\n",
      "I,J:  4 - 30\n",
      "I,J:  4 - 31\n",
      "Best_I:  4 Best_J:  6 Best_Score:  0.5917714134116774 Actual_Score:  0.5561867926984743\n",
      "I,J:  5 - 1\n",
      "I,J:  5 - 2\n",
      "I,J:  5 - 3\n",
      "I,J:  5 - 4\n",
      "I,J:  5 - 5\n",
      "I,J:  5 - 6\n",
      "I,J:  5 - 7\n",
      "I,J:  5 - 8\n",
      "I,J:  5 - 9\n",
      "I,J:  5 - 10\n",
      "I,J:  5 - 11\n",
      "I,J:  5 - 12\n",
      "I,J:  5 - 13\n",
      "I,J:  5 - 14\n",
      "I,J:  5 - 15\n",
      "I,J:  5 - 16\n",
      "I,J:  5 - 17\n",
      "I,J:  5 - 18\n",
      "I,J:  5 - 19\n",
      "I,J:  5 - 20\n",
      "I,J:  5 - 21\n",
      "I,J:  5 - 22\n",
      "I,J:  5 - 23\n",
      "I,J:  5 - 24\n",
      "I,J:  5 - 25\n",
      "I,J:  5 - 26\n",
      "I,J:  5 - 27\n",
      "I,J:  5 - 28\n",
      "I,J:  5 - 29\n",
      "I,J:  5 - 30\n",
      "I,J:  5 - 31\n",
      "Best_I:  5 Best_J:  31 Best_Score:  0.6055600317372198 Actual_Score:  0.6055600317372198\n",
      "I,J:  6 - 1\n",
      "I,J:  6 - 2\n",
      "I,J:  6 - 3\n",
      "I,J:  6 - 4\n",
      "I,J:  6 - 5\n",
      "I,J:  6 - 6\n",
      "I,J:  6 - 7\n",
      "I,J:  6 - 8\n",
      "I,J:  6 - 9\n",
      "I,J:  6 - 10\n",
      "I,J:  6 - 11\n",
      "I,J:  6 - 12\n",
      "I,J:  6 - 13\n",
      "I,J:  6 - 14\n",
      "I,J:  6 - 15\n",
      "I,J:  6 - 16\n",
      "I,J:  6 - 17\n",
      "I,J:  6 - 18\n",
      "I,J:  6 - 19\n",
      "I,J:  6 - 20\n",
      "I,J:  6 - 21\n",
      "I,J:  6 - 22\n",
      "I,J:  6 - 23\n",
      "I,J:  6 - 24\n",
      "I,J:  6 - 25\n",
      "I,J:  6 - 26\n",
      "I,J:  6 - 27\n",
      "I,J:  6 - 28\n",
      "I,J:  6 - 29\n",
      "I,J:  6 - 30\n",
      "I,J:  6 - 31\n",
      "Best_I:  5 Best_J:  31 Best_Score:  0.6055600317372198 Actual_Score:  0.5415614491037674\n",
      "I,J:  7 - 1\n",
      "I,J:  7 - 2\n",
      "I,J:  7 - 3\n",
      "I,J:  7 - 4\n",
      "I,J:  7 - 5\n",
      "I,J:  7 - 6\n",
      "I,J:  7 - 7\n",
      "I,J:  7 - 8\n",
      "I,J:  7 - 9\n",
      "I,J:  7 - 10\n",
      "I,J:  7 - 11\n",
      "I,J:  7 - 12\n",
      "I,J:  7 - 13\n",
      "I,J:  7 - 14\n",
      "I,J:  7 - 15\n",
      "I,J:  7 - 16\n",
      "I,J:  7 - 17\n",
      "I,J:  7 - 18\n",
      "I,J:  7 - 19\n",
      "I,J:  7 - 20\n",
      "I,J:  7 - 21\n",
      "I,J:  7 - 22\n",
      "I,J:  7 - 23\n",
      "I,J:  7 - 24\n",
      "I,J:  7 - 25\n",
      "I,J:  7 - 26\n",
      "I,J:  7 - 27\n",
      "I,J:  7 - 28\n",
      "I,J:  7 - 29\n",
      "I,J:  7 - 30\n",
      "I,J:  7 - 31\n",
      "Best_I:  5 Best_J:  31 Best_Score:  0.6055600317372198 Actual_Score:  0.562801988734761\n",
      "I,J:  8 - 1\n",
      "I,J:  8 - 2\n",
      "I,J:  8 - 3\n",
      "I,J:  8 - 4\n",
      "I,J:  8 - 5\n",
      "I,J:  8 - 6\n",
      "I,J:  8 - 7\n",
      "I,J:  8 - 8\n",
      "I,J:  8 - 9\n",
      "I,J:  8 - 10\n",
      "I,J:  8 - 11\n",
      "I,J:  8 - 12\n",
      "I,J:  8 - 13\n",
      "I,J:  8 - 14\n",
      "I,J:  8 - 15\n",
      "I,J:  8 - 16\n",
      "I,J:  8 - 17\n",
      "I,J:  8 - 18\n",
      "I,J:  8 - 19\n",
      "I,J:  8 - 20\n",
      "I,J:  8 - 21\n",
      "I,J:  8 - 22\n",
      "I,J:  8 - 23\n",
      "I,J:  8 - 24\n",
      "I,J:  8 - 25\n",
      "I,J:  8 - 26\n",
      "I,J:  8 - 27\n",
      "I,J:  8 - 28\n",
      "I,J:  8 - 29\n",
      "I,J:  8 - 30\n",
      "I,J:  8 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5568245462339072\n",
      "I,J:  9 - 1\n",
      "I,J:  9 - 2\n",
      "I,J:  9 - 3\n",
      "I,J:  9 - 4\n",
      "I,J:  9 - 5\n",
      "I,J:  9 - 6\n",
      "I,J:  9 - 7\n",
      "I,J:  9 - 8\n",
      "I,J:  9 - 9\n",
      "I,J:  9 - 10\n",
      "I,J:  9 - 11\n",
      "I,J:  9 - 12\n",
      "I,J:  9 - 13\n",
      "I,J:  9 - 14\n",
      "I,J:  9 - 15\n",
      "I,J:  9 - 16\n",
      "I,J:  9 - 17\n",
      "I,J:  9 - 18\n",
      "I,J:  9 - 19\n",
      "I,J:  9 - 20\n",
      "I,J:  9 - 21\n",
      "I,J:  9 - 22\n",
      "I,J:  9 - 23\n",
      "I,J:  9 - 24\n",
      "I,J:  9 - 25\n",
      "I,J:  9 - 26\n",
      "I,J:  9 - 27\n",
      "I,J:  9 - 28\n",
      "I,J:  9 - 29\n",
      "I,J:  9 - 30\n",
      "I,J:  9 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5148884898536698\n",
      "I,J:  10 - 1\n",
      "I,J:  10 - 2\n",
      "I,J:  10 - 3\n",
      "I,J:  10 - 4\n",
      "I,J:  10 - 5\n",
      "I,J:  10 - 6\n",
      "I,J:  10 - 7\n",
      "I,J:  10 - 8\n",
      "I,J:  10 - 9\n",
      "I,J:  10 - 10\n",
      "I,J:  10 - 11\n",
      "I,J:  10 - 12\n",
      "I,J:  10 - 13\n",
      "I,J:  10 - 14\n",
      "I,J:  10 - 15\n",
      "I,J:  10 - 16\n",
      "I,J:  10 - 17\n",
      "I,J:  10 - 18\n",
      "I,J:  10 - 19\n",
      "I,J:  10 - 20\n",
      "I,J:  10 - 21\n",
      "I,J:  10 - 22\n",
      "I,J:  10 - 23\n",
      "I,J:  10 - 24\n",
      "I,J:  10 - 25\n",
      "I,J:  10 - 26\n",
      "I,J:  10 - 27\n",
      "I,J:  10 - 28\n",
      "I,J:  10 - 29\n",
      "I,J:  10 - 30\n",
      "I,J:  10 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5424482243615095\n",
      "I,J:  11 - 1\n",
      "I,J:  11 - 2\n",
      "I,J:  11 - 3\n",
      "I,J:  11 - 4\n",
      "I,J:  11 - 5\n",
      "I,J:  11 - 6\n",
      "I,J:  11 - 7\n",
      "I,J:  11 - 8\n",
      "I,J:  11 - 9\n",
      "I,J:  11 - 10\n",
      "I,J:  11 - 11\n",
      "I,J:  11 - 12\n",
      "I,J:  11 - 13\n",
      "I,J:  11 - 14\n",
      "I,J:  11 - 15\n",
      "I,J:  11 - 16\n",
      "I,J:  11 - 17\n",
      "I,J:  11 - 18\n",
      "I,J:  11 - 19\n",
      "I,J:  11 - 20\n",
      "I,J:  11 - 21\n",
      "I,J:  11 - 22\n",
      "I,J:  11 - 23\n",
      "I,J:  11 - 24\n",
      "I,J:  11 - 25\n",
      "I,J:  11 - 26\n",
      "I,J:  11 - 27\n",
      "I,J:  11 - 28\n",
      "I,J:  11 - 29\n",
      "I,J:  11 - 30\n",
      "I,J:  11 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5535697617006433\n",
      "I,J:  12 - 1\n",
      "I,J:  12 - 2\n",
      "I,J:  12 - 3\n",
      "I,J:  12 - 4\n",
      "I,J:  12 - 5\n",
      "I,J:  12 - 6\n",
      "I,J:  12 - 7\n",
      "I,J:  12 - 8\n",
      "I,J:  12 - 9\n",
      "I,J:  12 - 10\n",
      "I,J:  12 - 11\n",
      "I,J:  12 - 12\n",
      "I,J:  12 - 13\n",
      "I,J:  12 - 14\n",
      "I,J:  12 - 15\n",
      "I,J:  12 - 16\n",
      "I,J:  12 - 17\n",
      "I,J:  12 - 18\n",
      "I,J:  12 - 19\n",
      "I,J:  12 - 20\n",
      "I,J:  12 - 21\n",
      "I,J:  12 - 22\n",
      "I,J:  12 - 23\n",
      "I,J:  12 - 24\n",
      "I,J:  12 - 25\n",
      "I,J:  12 - 26\n",
      "I,J:  12 - 27\n",
      "I,J:  12 - 28\n",
      "I,J:  12 - 29\n",
      "I,J:  12 - 30\n",
      "I,J:  12 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5444173690041342\n",
      "I,J:  13 - 1\n",
      "I,J:  13 - 2\n",
      "I,J:  13 - 3\n",
      "I,J:  13 - 4\n",
      "I,J:  13 - 5\n",
      "I,J:  13 - 6\n",
      "I,J:  13 - 7\n",
      "I,J:  13 - 8\n",
      "I,J:  13 - 9\n",
      "I,J:  13 - 10\n",
      "I,J:  13 - 11\n",
      "I,J:  13 - 12\n",
      "I,J:  13 - 13\n",
      "I,J:  13 - 14\n",
      "I,J:  13 - 15\n",
      "I,J:  13 - 16\n",
      "I,J:  13 - 17\n",
      "I,J:  13 - 18\n",
      "I,J:  13 - 19\n",
      "I,J:  13 - 20\n",
      "I,J:  13 - 21\n",
      "I,J:  13 - 22\n",
      "I,J:  13 - 23\n",
      "I,J:  13 - 24\n",
      "I,J:  13 - 25\n",
      "I,J:  13 - 26\n",
      "I,J:  13 - 27\n",
      "I,J:  13 - 28\n",
      "I,J:  13 - 29\n",
      "I,J:  13 - 30\n",
      "I,J:  13 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5382105563102288\n",
      "I,J:  14 - 1\n",
      "I,J:  14 - 2\n",
      "I,J:  14 - 3\n",
      "I,J:  14 - 4\n",
      "I,J:  14 - 5\n",
      "I,J:  14 - 6\n",
      "I,J:  14 - 7\n",
      "I,J:  14 - 8\n",
      "I,J:  14 - 9\n",
      "I,J:  14 - 10\n",
      "I,J:  14 - 11\n",
      "I,J:  14 - 12\n",
      "I,J:  14 - 13\n",
      "I,J:  14 - 14\n",
      "I,J:  14 - 15\n",
      "I,J:  14 - 16\n",
      "I,J:  14 - 17\n",
      "I,J:  14 - 18\n",
      "I,J:  14 - 19\n",
      "I,J:  14 - 20\n",
      "I,J:  14 - 21\n",
      "I,J:  14 - 22\n",
      "I,J:  14 - 23\n",
      "I,J:  14 - 24\n",
      "I,J:  14 - 25\n",
      "I,J:  14 - 26\n",
      "I,J:  14 - 27\n",
      "I,J:  14 - 28\n",
      "I,J:  14 - 29\n",
      "I,J:  14 - 30\n",
      "I,J:  14 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5394961962008681\n",
      "I,J:  15 - 1\n",
      "I,J:  15 - 2\n",
      "I,J:  15 - 3\n",
      "I,J:  15 - 4\n",
      "I,J:  15 - 5\n",
      "I,J:  15 - 6\n",
      "I,J:  15 - 7\n",
      "I,J:  15 - 8\n",
      "I,J:  15 - 9\n",
      "I,J:  15 - 10\n",
      "I,J:  15 - 11\n",
      "I,J:  15 - 12\n",
      "I,J:  15 - 13\n",
      "I,J:  15 - 14\n",
      "I,J:  15 - 15\n",
      "I,J:  15 - 16\n",
      "I,J:  15 - 17\n",
      "I,J:  15 - 18\n",
      "I,J:  15 - 19\n",
      "I,J:  15 - 20\n",
      "I,J:  15 - 21\n",
      "I,J:  15 - 22\n",
      "I,J:  15 - 23\n",
      "I,J:  15 - 24\n",
      "I,J:  15 - 25\n",
      "I,J:  15 - 26\n",
      "I,J:  15 - 27\n",
      "I,J:  15 - 28\n",
      "I,J:  15 - 29\n",
      "I,J:  15 - 30\n",
      "I,J:  15 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5698974190172762\n",
      "I,J:  16 - 1\n",
      "I,J:  16 - 2\n",
      "I,J:  16 - 3\n",
      "I,J:  16 - 4\n",
      "I,J:  16 - 5\n",
      "I,J:  16 - 6\n",
      "I,J:  16 - 7\n",
      "I,J:  16 - 8\n",
      "I,J:  16 - 9\n",
      "I,J:  16 - 10\n",
      "I,J:  16 - 11\n",
      "I,J:  16 - 12\n",
      "I,J:  16 - 13\n",
      "I,J:  16 - 14\n",
      "I,J:  16 - 15\n",
      "I,J:  16 - 16\n",
      "I,J:  16 - 17\n",
      "I,J:  16 - 18\n",
      "I,J:  16 - 19\n",
      "I,J:  16 - 20\n",
      "I,J:  16 - 21\n",
      "I,J:  16 - 22\n",
      "I,J:  16 - 23\n",
      "I,J:  16 - 24\n",
      "I,J:  16 - 25\n",
      "I,J:  16 - 26\n",
      "I,J:  16 - 27\n",
      "I,J:  16 - 28\n",
      "I,J:  16 - 29\n",
      "I,J:  16 - 30\n",
      "I,J:  16 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5635555020597258\n",
      "I,J:  17 - 1\n",
      "I,J:  17 - 2\n",
      "I,J:  17 - 3\n",
      "I,J:  17 - 4\n",
      "I,J:  17 - 5\n",
      "I,J:  17 - 6\n",
      "I,J:  17 - 7\n",
      "I,J:  17 - 8\n",
      "I,J:  17 - 9\n",
      "I,J:  17 - 10\n",
      "I,J:  17 - 11\n",
      "I,J:  17 - 12\n",
      "I,J:  17 - 13\n",
      "I,J:  17 - 14\n",
      "I,J:  17 - 15\n",
      "I,J:  17 - 16\n",
      "I,J:  17 - 17\n",
      "I,J:  17 - 18\n",
      "I,J:  17 - 19\n",
      "I,J:  17 - 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,J:  17 - 21\n",
      "I,J:  17 - 22\n",
      "I,J:  17 - 23\n",
      "I,J:  17 - 24\n",
      "I,J:  17 - 25\n",
      "I,J:  17 - 26\n",
      "I,J:  17 - 27\n",
      "I,J:  17 - 28\n",
      "I,J:  17 - 29\n",
      "I,J:  17 - 30\n",
      "I,J:  17 - 31\n",
      "Best_I:  8 Best_J:  24 Best_Score:  0.6383338696563192 Actual_Score:  0.5396214746998843\n",
      "I,J:  18 - 1\n",
      "I,J:  18 - 2\n",
      "I,J:  18 - 3\n",
      "I,J:  18 - 4\n",
      "I,J:  18 - 5\n",
      "I,J:  18 - 6\n",
      "I,J:  18 - 7\n",
      "I,J:  18 - 8\n",
      "I,J:  18 - 9\n",
      "I,J:  18 - 10\n",
      "I,J:  18 - 11\n",
      "I,J:  18 - 12\n",
      "I,J:  18 - 13\n",
      "I,J:  18 - 14\n",
      "I,J:  18 - 15\n",
      "I,J:  18 - 16\n",
      "I,J:  18 - 17\n",
      "I,J:  18 - 18\n",
      "I,J:  18 - 19\n",
      "I,J:  18 - 20\n",
      "I,J:  18 - 21\n",
      "I,J:  18 - 22\n",
      "I,J:  18 - 23\n",
      "I,J:  18 - 24\n",
      "I,J:  18 - 25\n",
      "I,J:  18 - 26\n",
      "I,J:  18 - 27\n",
      "I,J:  18 - 28\n",
      "I,J:  18 - 29\n",
      "I,J:  18 - 30\n",
      "I,J:  18 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5208398326672283\n",
      "I,J:  19 - 1\n",
      "I,J:  19 - 2\n",
      "I,J:  19 - 3\n",
      "I,J:  19 - 4\n",
      "I,J:  19 - 5\n",
      "I,J:  19 - 6\n",
      "I,J:  19 - 7\n",
      "I,J:  19 - 8\n",
      "I,J:  19 - 9\n",
      "I,J:  19 - 10\n",
      "I,J:  19 - 11\n",
      "I,J:  19 - 12\n",
      "I,J:  19 - 13\n",
      "I,J:  19 - 14\n",
      "I,J:  19 - 15\n",
      "I,J:  19 - 16\n",
      "I,J:  19 - 17\n",
      "I,J:  19 - 18\n",
      "I,J:  19 - 19\n",
      "I,J:  19 - 20\n",
      "I,J:  19 - 21\n",
      "I,J:  19 - 22\n",
      "I,J:  19 - 23\n",
      "I,J:  19 - 24\n",
      "I,J:  19 - 25\n",
      "I,J:  19 - 26\n",
      "I,J:  19 - 27\n",
      "I,J:  19 - 28\n",
      "I,J:  19 - 29\n",
      "I,J:  19 - 30\n",
      "I,J:  19 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5428274374651493\n",
      "I,J:  20 - 1\n",
      "I,J:  20 - 2\n",
      "I,J:  20 - 3\n",
      "I,J:  20 - 4\n",
      "I,J:  20 - 5\n",
      "I,J:  20 - 6\n",
      "I,J:  20 - 7\n",
      "I,J:  20 - 8\n",
      "I,J:  20 - 9\n",
      "I,J:  20 - 10\n",
      "I,J:  20 - 11\n",
      "I,J:  20 - 12\n",
      "I,J:  20 - 13\n",
      "I,J:  20 - 14\n",
      "I,J:  20 - 15\n",
      "I,J:  20 - 16\n",
      "I,J:  20 - 17\n",
      "I,J:  20 - 18\n",
      "I,J:  20 - 19\n",
      "I,J:  20 - 20\n",
      "I,J:  20 - 21\n",
      "I,J:  20 - 22\n",
      "I,J:  20 - 23\n",
      "I,J:  20 - 24\n",
      "I,J:  20 - 25\n",
      "I,J:  20 - 26\n",
      "I,J:  20 - 27\n",
      "I,J:  20 - 28\n",
      "I,J:  20 - 29\n",
      "I,J:  20 - 30\n",
      "I,J:  20 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.567033208628004\n",
      "I,J:  21 - 1\n",
      "I,J:  21 - 2\n",
      "I,J:  21 - 3\n",
      "I,J:  21 - 4\n",
      "I,J:  21 - 5\n",
      "I,J:  21 - 6\n",
      "I,J:  21 - 7\n",
      "I,J:  21 - 8\n",
      "I,J:  21 - 9\n",
      "I,J:  21 - 10\n",
      "I,J:  21 - 11\n",
      "I,J:  21 - 12\n",
      "I,J:  21 - 13\n",
      "I,J:  21 - 14\n",
      "I,J:  21 - 15\n",
      "I,J:  21 - 16\n",
      "I,J:  21 - 17\n",
      "I,J:  21 - 18\n",
      "I,J:  21 - 19\n",
      "I,J:  21 - 20\n",
      "I,J:  21 - 21\n",
      "I,J:  21 - 22\n",
      "I,J:  21 - 23\n",
      "I,J:  21 - 24\n",
      "I,J:  21 - 25\n",
      "I,J:  21 - 26\n",
      "I,J:  21 - 27\n",
      "I,J:  21 - 28\n",
      "I,J:  21 - 29\n",
      "I,J:  21 - 30\n",
      "I,J:  21 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5263566924511106\n",
      "I,J:  22 - 1\n",
      "I,J:  22 - 2\n",
      "I,J:  22 - 3\n",
      "I,J:  22 - 4\n",
      "I,J:  22 - 5\n",
      "I,J:  22 - 6\n",
      "I,J:  22 - 7\n",
      "I,J:  22 - 8\n",
      "I,J:  22 - 9\n",
      "I,J:  22 - 10\n",
      "I,J:  22 - 11\n",
      "I,J:  22 - 12\n",
      "I,J:  22 - 13\n",
      "I,J:  22 - 14\n",
      "I,J:  22 - 15\n",
      "I,J:  22 - 16\n",
      "I,J:  22 - 17\n",
      "I,J:  22 - 18\n",
      "I,J:  22 - 19\n",
      "I,J:  22 - 20\n",
      "I,J:  22 - 21\n",
      "I,J:  22 - 22\n",
      "I,J:  22 - 23\n",
      "I,J:  22 - 24\n",
      "I,J:  22 - 25\n",
      "I,J:  22 - 26\n",
      "I,J:  22 - 27\n",
      "I,J:  22 - 28\n",
      "I,J:  22 - 29\n",
      "I,J:  22 - 30\n",
      "I,J:  22 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5375107776355771\n",
      "I,J:  23 - 1\n",
      "I,J:  23 - 2\n",
      "I,J:  23 - 3\n",
      "I,J:  23 - 4\n",
      "I,J:  23 - 5\n",
      "I,J:  23 - 6\n",
      "I,J:  23 - 7\n",
      "I,J:  23 - 8\n",
      "I,J:  23 - 9\n",
      "I,J:  23 - 10\n",
      "I,J:  23 - 11\n",
      "I,J:  23 - 12\n",
      "I,J:  23 - 13\n",
      "I,J:  23 - 14\n",
      "I,J:  23 - 15\n",
      "I,J:  23 - 16\n",
      "I,J:  23 - 17\n",
      "I,J:  23 - 18\n",
      "I,J:  23 - 19\n",
      "I,J:  23 - 20\n",
      "I,J:  23 - 21\n",
      "I,J:  23 - 22\n",
      "I,J:  23 - 23\n",
      "I,J:  23 - 24\n",
      "I,J:  23 - 25\n",
      "I,J:  23 - 26\n",
      "I,J:  23 - 27\n",
      "I,J:  23 - 28\n",
      "I,J:  23 - 29\n",
      "I,J:  23 - 30\n",
      "I,J:  23 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5644392067660216\n",
      "I,J:  24 - 1\n",
      "I,J:  24 - 2\n",
      "I,J:  24 - 3\n",
      "I,J:  24 - 4\n",
      "I,J:  24 - 5\n",
      "I,J:  24 - 6\n",
      "I,J:  24 - 7\n",
      "I,J:  24 - 8\n",
      "I,J:  24 - 9\n",
      "I,J:  24 - 10\n",
      "I,J:  24 - 11\n",
      "I,J:  24 - 12\n",
      "I,J:  24 - 13\n",
      "I,J:  24 - 14\n",
      "I,J:  24 - 15\n",
      "I,J:  24 - 16\n",
      "I,J:  24 - 17\n",
      "I,J:  24 - 18\n",
      "I,J:  24 - 19\n",
      "I,J:  24 - 20\n",
      "I,J:  24 - 21\n",
      "I,J:  24 - 22\n",
      "I,J:  24 - 23\n",
      "I,J:  24 - 24\n",
      "I,J:  24 - 25\n",
      "I,J:  24 - 26\n",
      "I,J:  24 - 27\n",
      "I,J:  24 - 28\n",
      "I,J:  24 - 29\n",
      "I,J:  24 - 30\n",
      "I,J:  24 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5245616480755011\n",
      "I,J:  25 - 1\n",
      "I,J:  25 - 2\n",
      "I,J:  25 - 3\n",
      "I,J:  25 - 4\n",
      "I,J:  25 - 5\n",
      "I,J:  25 - 6\n",
      "I,J:  25 - 7\n",
      "I,J:  25 - 8\n",
      "I,J:  25 - 9\n",
      "I,J:  25 - 10\n",
      "I,J:  25 - 11\n",
      "I,J:  25 - 12\n",
      "I,J:  25 - 13\n",
      "I,J:  25 - 14\n",
      "I,J:  25 - 15\n",
      "I,J:  25 - 16\n",
      "I,J:  25 - 17\n",
      "I,J:  25 - 18\n",
      "I,J:  25 - 19\n",
      "I,J:  25 - 20\n",
      "I,J:  25 - 21\n",
      "I,J:  25 - 22\n",
      "I,J:  25 - 23\n",
      "I,J:  25 - 24\n",
      "I,J:  25 - 25\n",
      "I,J:  25 - 26\n",
      "I,J:  25 - 27\n",
      "I,J:  25 - 28\n",
      "I,J:  25 - 29\n",
      "I,J:  25 - 30\n",
      "I,J:  25 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5569808373025328\n",
      "I,J:  26 - 1\n",
      "I,J:  26 - 2\n",
      "I,J:  26 - 3\n",
      "I,J:  26 - 4\n",
      "I,J:  26 - 5\n",
      "I,J:  26 - 6\n",
      "I,J:  26 - 7\n",
      "I,J:  26 - 8\n",
      "I,J:  26 - 9\n",
      "I,J:  26 - 10\n",
      "I,J:  26 - 11\n",
      "I,J:  26 - 12\n",
      "I,J:  26 - 13\n",
      "I,J:  26 - 14\n",
      "I,J:  26 - 15\n",
      "I,J:  26 - 16\n",
      "I,J:  26 - 17\n",
      "I,J:  26 - 18\n",
      "I,J:  26 - 19\n",
      "I,J:  26 - 20\n",
      "I,J:  26 - 21\n",
      "I,J:  26 - 22\n",
      "I,J:  26 - 23\n",
      "I,J:  26 - 24\n",
      "I,J:  26 - 25\n",
      "I,J:  26 - 26\n",
      "I,J:  26 - 27\n",
      "I,J:  26 - 28\n",
      "I,J:  26 - 29\n",
      "I,J:  26 - 30\n",
      "I,J:  26 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5453271733977249\n",
      "I,J:  27 - 1\n",
      "I,J:  27 - 2\n",
      "I,J:  27 - 3\n",
      "I,J:  27 - 4\n",
      "I,J:  27 - 5\n",
      "I,J:  27 - 6\n",
      "I,J:  27 - 7\n",
      "I,J:  27 - 8\n",
      "I,J:  27 - 9\n",
      "I,J:  27 - 10\n",
      "I,J:  27 - 11\n",
      "I,J:  27 - 12\n",
      "I,J:  27 - 13\n",
      "I,J:  27 - 14\n",
      "I,J:  27 - 15\n",
      "I,J:  27 - 16\n",
      "I,J:  27 - 17\n",
      "I,J:  27 - 18\n",
      "I,J:  27 - 19\n",
      "I,J:  27 - 20\n",
      "I,J:  27 - 21\n",
      "I,J:  27 - 22\n",
      "I,J:  27 - 23\n",
      "I,J:  27 - 24\n",
      "I,J:  27 - 25\n",
      "I,J:  27 - 26\n",
      "I,J:  27 - 27\n",
      "I,J:  27 - 28\n",
      "I,J:  27 - 29\n",
      "I,J:  27 - 30\n",
      "I,J:  27 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5546536663612491\n",
      "I,J:  28 - 1\n",
      "I,J:  28 - 2\n",
      "I,J:  28 - 3\n",
      "I,J:  28 - 4\n",
      "I,J:  28 - 5\n",
      "I,J:  28 - 6\n",
      "I,J:  28 - 7\n",
      "I,J:  28 - 8\n",
      "I,J:  28 - 9\n",
      "I,J:  28 - 10\n",
      "I,J:  28 - 11\n",
      "I,J:  28 - 12\n",
      "I,J:  28 - 13\n",
      "I,J:  28 - 14\n",
      "I,J:  28 - 15\n",
      "I,J:  28 - 16\n",
      "I,J:  28 - 17\n",
      "I,J:  28 - 18\n",
      "I,J:  28 - 19\n",
      "I,J:  28 - 20\n",
      "I,J:  28 - 21\n",
      "I,J:  28 - 22\n",
      "I,J:  28 - 23\n",
      "I,J:  28 - 24\n",
      "I,J:  28 - 25\n",
      "I,J:  28 - 26\n",
      "I,J:  28 - 27\n",
      "I,J:  28 - 28\n",
      "I,J:  28 - 29\n",
      "I,J:  28 - 30\n",
      "I,J:  28 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5626278884677457\n",
      "I,J:  29 - 1\n",
      "I,J:  29 - 2\n",
      "I,J:  29 - 3\n",
      "I,J:  29 - 4\n",
      "I,J:  29 - 5\n",
      "I,J:  29 - 6\n",
      "I,J:  29 - 7\n",
      "I,J:  29 - 8\n",
      "I,J:  29 - 9\n",
      "I,J:  29 - 10\n",
      "I,J:  29 - 11\n",
      "I,J:  29 - 12\n",
      "I,J:  29 - 13\n",
      "I,J:  29 - 14\n",
      "I,J:  29 - 15\n",
      "I,J:  29 - 16\n",
      "I,J:  29 - 17\n",
      "I,J:  29 - 18\n",
      "I,J:  29 - 19\n",
      "I,J:  29 - 20\n",
      "I,J:  29 - 21\n",
      "I,J:  29 - 22\n",
      "I,J:  29 - 23\n",
      "I,J:  29 - 24\n",
      "I,J:  29 - 25\n",
      "I,J:  29 - 26\n",
      "I,J:  29 - 27\n",
      "I,J:  29 - 28\n",
      "I,J:  29 - 29\n",
      "I,J:  29 - 30\n",
      "I,J:  29 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5416231671878416\n",
      "I,J:  30 - 1\n",
      "I,J:  30 - 2\n",
      "I,J:  30 - 3\n",
      "I,J:  30 - 4\n",
      "I,J:  30 - 5\n",
      "I,J:  30 - 6\n",
      "I,J:  30 - 7\n",
      "I,J:  30 - 8\n",
      "I,J:  30 - 9\n",
      "I,J:  30 - 10\n",
      "I,J:  30 - 11\n",
      "I,J:  30 - 12\n",
      "I,J:  30 - 13\n",
      "I,J:  30 - 14\n",
      "I,J:  30 - 15\n",
      "I,J:  30 - 16\n",
      "I,J:  30 - 17\n",
      "I,J:  30 - 18\n",
      "I,J:  30 - 19\n",
      "I,J:  30 - 20\n",
      "I,J:  30 - 21\n",
      "I,J:  30 - 22\n",
      "I,J:  30 - 23\n",
      "I,J:  30 - 24\n",
      "I,J:  30 - 25\n",
      "I,J:  30 - 26\n",
      "I,J:  30 - 27\n",
      "I,J:  30 - 28\n",
      "I,J:  30 - 29\n",
      "I,J:  30 - 30\n",
      "I,J:  30 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5027969653125943\n",
      "I,J:  31 - 1\n",
      "I,J:  31 - 2\n",
      "I,J:  31 - 3\n",
      "I,J:  31 - 4\n",
      "I,J:  31 - 5\n",
      "I,J:  31 - 6\n",
      "I,J:  31 - 7\n",
      "I,J:  31 - 8\n",
      "I,J:  31 - 9\n",
      "I,J:  31 - 10\n",
      "I,J:  31 - 11\n",
      "I,J:  31 - 12\n",
      "I,J:  31 - 13\n",
      "I,J:  31 - 14\n",
      "I,J:  31 - 15\n",
      "I,J:  31 - 16\n",
      "I,J:  31 - 17\n",
      "I,J:  31 - 18\n",
      "I,J:  31 - 19\n",
      "I,J:  31 - 20\n",
      "I,J:  31 - 21\n",
      "I,J:  31 - 22\n",
      "I,J:  31 - 23\n",
      "I,J:  31 - 24\n",
      "I,J:  31 - 25\n",
      "I,J:  31 - 26\n",
      "I,J:  31 - 27\n",
      "I,J:  31 - 28\n",
      "I,J:  31 - 29\n",
      "I,J:  31 - 30\n",
      "I,J:  31 - 31\n",
      "Best_I:  18 Best_J:  2 Best_Score:  0.6460053353901933 Actual_Score:  0.5192010793602444\n",
      "Best_I:  18 Best_I:  2 Best_Score:  0.6460053353901933\n"
     ]
    }
   ],
   "source": [
    "best_score_twol = actual_score = 0\n",
    "best_i_twol = best_j_twol = 0\n",
    "for i in range(1,32,1):\n",
    "    for j in range(1,32,1):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(i,j,), max_iter=200000,verbose=False)\n",
    "        mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "        predictions = mlp.predict(df_X_val.values)\n",
    "        fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "        actual_score = auc(fpr, tpr)\n",
    "        if actual_score > best_score_twol:\n",
    "            best_score_twol = actual_score\n",
    "            best_i_twol = i\n",
    "            best_j_twol = j\n",
    "        print(\"I,J: \", i,\"-\",j)\n",
    "    print(\"Best_I: \", best_i_twol,\"Best_J: \", best_j_twol,\"Best_Score: \", best_score_twol,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_I: \",best_i_twol,\"Best_I: \",best_j_twol,\"Best_Score: \", best_score_twol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Find the best random state for both single layer and two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  1 Best_Random_State:  1 Best_Score:  0.5494297371853606 Actual_Score:  0.5494297371853606\n",
      "I:  2 Best_Random_State:  2 Best_Score:  0.5746543173181557 Actual_Score:  0.5746543173181557\n",
      "I:  3 Best_Random_State:  2 Best_Score:  0.5746543173181557 Actual_Score:  0.5471400269717239\n",
      "I:  4 Best_Random_State:  2 Best_Score:  0.5746543173181557 Actual_Score:  0.5367996379205734\n",
      "I:  5 Best_Random_State:  2 Best_Score:  0.5746543173181557 Actual_Score:  0.5420186542141475\n",
      "I:  6 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.598975541215398\n",
      "I:  7 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5741172778701673\n",
      "I:  8 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5677655351479882\n",
      "I:  9 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5707160280329064\n",
      "I:  10 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5802215341457604\n",
      "I:  11 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5017115253762654\n",
      "I:  12 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5492068151503465\n",
      "I:  13 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5520433905766005\n",
      "I:  14 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5794941205080902\n",
      "I:  15 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5145304635550108\n",
      "I:  16 Best_Random_State:  6 Best_Score:  0.598975541215398 Actual_Score:  0.5783712198441142\n",
      "I:  17 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.6163511777407128\n",
      "I:  18 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5616026313397675\n",
      "I:  19 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5752303527695145\n",
      "I:  20 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5529547302459143\n",
      "I:  21 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5827439921590398\n",
      "I:  22 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5881257476792772\n",
      "I:  23 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5135865760403642\n",
      "I:  24 Best_Random_State:  17 Best_Score:  0.6163511777407128 Actual_Score:  0.5416443539928223\n",
      "I:  25 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.6199378888853406\n",
      "I:  26 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.6196986929276603\n",
      "I:  27 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5891396437669033\n",
      "I:  28 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5207308280908785\n",
      "I:  29 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5296879337153918\n",
      "I:  30 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5623837796277509\n",
      "I:  31 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5452897126700778\n",
      "I:  32 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5400056006858384\n",
      "I:  33 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5563949760865453\n",
      "I:  34 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5546097574755646\n",
      "I:  35 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5382919259235605\n",
      "I:  36 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5923406936498539\n",
      "I:  37 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5771344017214739\n",
      "I:  38 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5667728258653428\n",
      "I:  39 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5450732387931014\n",
      "I:  40 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.54857213216636\n",
      "I:  41 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5389917045982122\n",
      "I:  42 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5617279098387838\n",
      "I:  43 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5427460678518177\n",
      "I:  44 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5265357056004402\n",
      "I:  45 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5727339944435301\n",
      "I:  46 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5412537798488306\n",
      "I:  47 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.605008253642288\n",
      "I:  48 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5957794042147618\n",
      "I:  49 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5867897507449158\n",
      "I:  50 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5952211779617924\n",
      "I:  51 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5831182923803652\n",
      "I:  52 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5782410284627837\n",
      "I:  53 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.564715863451349\n",
      "I:  54 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5535958613879384\n",
      "I:  55 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.6141265632177415\n",
      "I:  56 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5812354302333864\n",
      "I:  57 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5730496471322277\n",
      "I:  58 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5762117010118082\n",
      "I:  59 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5570947547611971\n",
      "I:  60 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5738357083025254\n",
      "I:  61 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.5728869079055645\n",
      "I:  62 Best_Random_State:  25 Best_Score:  0.6199378888853406 Actual_Score:  0.6032393089539737\n",
      "I:  63 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.6214123676899381\n",
      "I:  64 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5883910433242527\n",
      "I:  65 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5236552212885016\n",
      "I:  66 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.504087518085548\n",
      "I:  67 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5135865760403642\n",
      "I:  68 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5200912322245776\n",
      "I:  69 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.56274180592641\n",
      "I:  70 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5606261959797884\n",
      "I:  71 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5546748531662299\n",
      "I:  72 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5179105265872909\n",
      "I:  73 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5325082352189794\n",
      "I:  74 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5718665636599009\n",
      "I:  75 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5753117223828461\n",
      "I:  76 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5606863787881393\n",
      "I:  77 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5620306662114063\n",
      "I:  78 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5803403644867389\n",
      "I:  79 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5421000238274791\n",
      "I:  80 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5628557233850741\n",
      "I:  81 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5641576371983797\n",
      "I:  82 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5292859985310482\n",
      "I:  83 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5452734387474115\n",
      "I:  84 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5964091743164339\n",
      "I:  85 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5706411065776125\n",
      "I:  86 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5278376194137457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  87 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5763858012788233\n",
      "I:  88 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5821142220573677\n",
      "I:  89 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5456802868140694\n",
      "I:  90 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5343471884802735\n",
      "I:  91 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5280491804084079\n",
      "I:  92 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5649713333316957\n",
      "I:  93 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5787943418334385\n",
      "I:  94 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5817073739907097\n",
      "I:  95 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.6069497633218945\n",
      "I:  96 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5753003613424943\n",
      "I:  97 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.5507804727666651\n",
      "I:  98 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.553356665430258\n",
      "I:  99 Best_Random_State:  63 Best_Score:  0.6214123676899381 Actual_Score:  0.523313468912509\n",
      "Best_Random_State:  63 Best_Score:  0.6214123676899381\n"
     ]
    }
   ],
   "source": [
    "best_score_sl = actual_score = 0\n",
    "best_random_state_sl = 0\n",
    "for i in range(1,100,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_sl,), max_iter=200000,verbose=False, random_state=i)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_sl:\n",
    "        best_score_sl = actual_score\n",
    "        best_random_state_sl = i\n",
    "    print(\"I: \", i, \"Best_Random_State: \",best_random_state_sl,\"Best_Score: \", best_score_sl,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_Random_State: \",best_random_state_sl,\"Best_Score: \", best_score_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (30777,18) and (16,18) not aligned: 18 (dim 1) != 16 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-89bc0aefd5e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_i_twol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_j_twol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_y_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mactual_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Python36/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \"\"\"\n\u001b[1;32m    952\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Python36/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    674\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Python36/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 102\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Python36/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (30777,18) and (16,18) not aligned: 18 (dim 1) != 16 (dim 0)"
     ]
    }
   ],
   "source": [
    "best_score_twol = actual_score = 0\n",
    "best_random_state_twol = 0\n",
    "for i in range(1,100,1):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_twol,best_j_twol), max_iter=200000,verbose=False, random_state=i)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "    predictions = mlp.predict(df_X_val.values)\n",
    "    fpr, tpr, thresholds = roc_curve(df_y_val['Class'].values, predictions, pos_label=1)\n",
    "    actual_score = auc(fpr, tpr)\n",
    "    if actual_score > best_score_twol:\n",
    "        best_score_twol = actual_score\n",
    "        best_random_state_twol = i\n",
    "    print(\"I: \", i, \"Best_Random_State: \",best_random_state_twol,\"Best_Score: \", best_score_twol,\"Actual_Score: \", actual_score)\n",
    "print(\"Best_Random_State: \",best_random_state_twol,\"Best_Score: \", best_score_twol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute metrics on the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best architecture is :  Two Layers\n",
      "For the layer  1  the best number of neurons is :  30\n"
     ]
    }
   ],
   "source": [
    "if best_score_sl > best_score_twol:\n",
    "    best_architecture = \"One Layers\"\n",
    "    best_neurons = [best_i_sl]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_sl,), max_iter=200000,verbose=False, random_state=best_random_state_sl)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "else:\n",
    "    best_architecture = \"Two Layers\"\n",
    "    best_neurons = [best_i_twol, best_j_twol]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_i_twol,best_j_twol), max_iter=200000,verbose=False, random_state=best_random_state_twol)\n",
    "    mlp.fit(df_X_train,df_y_train['Class'].values)\n",
    "\n",
    "predictions = mlp.predict(df_X_val.values)\n",
    "print(\"The best architecture is : \", best_architecture)\n",
    "layer = 0\n",
    "for neuron in best_neurons:\n",
    "    layer += 1\n",
    "    print(\"For the layer \", layer, \" the best number of neurons is : \", neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21953  8771]\n",
      " [   25    28]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(df_y_val['Class'].values,predictions)\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Fracture       1.00      0.71      0.83     30724\n",
      "    Fracture       0.00      0.53      0.01        53\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     30777\n",
      "   macro avg       0.50      0.62      0.42     30777\n",
      "weighted avg       1.00      0.71      0.83     30777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_y_val['Class'].values,predictions,target_names=['Non-Fracture','Fracture']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7142021639536017\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / float(tp+tn+fp+fn)\n",
    "print(\"Accuracy : \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Recall (or Sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall :  0.5283018867924528\n"
     ]
    }
   ],
   "source": [
    "recall = tp/(tp+fn)\n",
    "print(\"Recall : \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error :  0.2857978360463983\n"
     ]
    }
   ],
   "source": [
    "classification_error = (fp + fn) / float(tp+tn+fp+fn)\n",
    "print(\"Error : \",classification_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145228485874235\n"
     ]
    }
   ],
   "source": [
    "specificity = tn / (tn+fp)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 False Positive Rate: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2854771514125765\n",
      "0.28547715141257646\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = fp / float(tn+fp)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Precision: When a positive value is predicted, how often is the prediction correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031821797931583136\n"
     ]
    }
   ],
   "source": [
    "precision = tp / float(tp+fp)\n",
    "\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_y_val, predictions)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creation new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = pd.DataFrame(df_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>HIPX</th>\n",
       "      <th>menopause</th>\n",
       "      <th>HRT</th>\n",
       "      <th>smoking</th>\n",
       "      <th>ReumatoidArthritis</th>\n",
       "      <th>SecondaryOsteoporsis</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>VitaminD</th>\n",
       "      <th>calcium</th>\n",
       "      <th>dose_walk</th>\n",
       "      <th>dose_moderate</th>\n",
       "      <th>dose_vigorous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>-1.383228</td>\n",
       "      <td>-1.438686</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.141958</td>\n",
       "      <td>0.115530</td>\n",
       "      <td>-0.259297</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.538945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43265</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-1.957990</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>1.770734</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>1.276093</td>\n",
       "      <td>0.113305</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>0.201583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116861</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>1.145866</td>\n",
       "      <td>2.161613</td>\n",
       "      <td>1.498749</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>-0.366965</td>\n",
       "      <td>-0.493062</td>\n",
       "      <td>0.583416</td>\n",
       "      <td>-0.353813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46479</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-0.716448</td>\n",
       "      <td>-0.803047</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>2.330176</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>3.056626</td>\n",
       "      <td>-1.030506</td>\n",
       "      <td>-0.598176</td>\n",
       "      <td>-0.504194</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.168681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115581</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>-0.095676</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.737192</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>-0.874557</td>\n",
       "      <td>-0.343833</td>\n",
       "      <td>-0.593247</td>\n",
       "      <td>-0.562138</td>\n",
       "      <td>-0.508090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sex       age    weight    height      HIPX  menopause       HRT  \\\n",
       "149978 -1.029482  0.152632 -1.383228 -1.438686 -0.037838   1.436838 -0.423252   \n",
       "43265   0.971362 -1.957990  0.637841  1.770734 -0.037838  -0.695973 -0.423252   \n",
       "116861  0.971362  1.145866  2.161613  1.498749 -0.037838  -0.695973 -0.423252   \n",
       "46479   0.971362 -0.716448 -0.803047  0.845986 -0.037838  -0.695973 -0.423252   \n",
       "115581 -1.029482 -0.095676  0.274431  0.737192 -0.037838   1.436838 -0.423252   \n",
       "\n",
       "         smoking  ReumatoidArthritis  SecondaryOsteoporsis   Alcohol  \\\n",
       "149978 -0.808640            -0.08895             -0.134216 -0.612333   \n",
       "43265   0.760768            -0.08895             -0.134216  0.104979   \n",
       "116861  0.760768            -0.08895             -0.134216  0.104979   \n",
       "46479   2.330176            -0.08895             -0.134216  3.056626   \n",
       "115581 -0.808640            -0.08895             -0.134216  0.397031   \n",
       "\n",
       "        VitaminD   calcium  dose_walk  dose_moderate  dose_vigorous  \n",
       "149978 -0.141958  0.115530  -0.259297      -0.462525      -0.538945  \n",
       "43265   1.276093  0.113305  -0.637774      -0.611945       0.201583  \n",
       "116861 -0.504631 -0.366965  -0.493062       0.583416      -0.353813  \n",
       "46479  -1.030506 -0.598176  -0.504194      -0.462525      -0.168681  \n",
       "115581 -0.874557 -0.343833  -0.593247      -0.562138      -0.508090  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df['real_class'] = df_y_val\n",
    "mod_df['predicted_class'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>HIPX</th>\n",
       "      <th>menopause</th>\n",
       "      <th>HRT</th>\n",
       "      <th>smoking</th>\n",
       "      <th>ReumatoidArthritis</th>\n",
       "      <th>SecondaryOsteoporsis</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>VitaminD</th>\n",
       "      <th>calcium</th>\n",
       "      <th>dose_walk</th>\n",
       "      <th>dose_moderate</th>\n",
       "      <th>dose_vigorous</th>\n",
       "      <th>real_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>-1.383228</td>\n",
       "      <td>-1.438686</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.141958</td>\n",
       "      <td>0.115530</td>\n",
       "      <td>-0.259297</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.538945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43265</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-1.957990</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>1.770734</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>1.276093</td>\n",
       "      <td>0.113305</td>\n",
       "      <td>-0.637774</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116861</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>1.145866</td>\n",
       "      <td>2.161613</td>\n",
       "      <td>1.498749</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>-0.366965</td>\n",
       "      <td>-0.493062</td>\n",
       "      <td>0.583416</td>\n",
       "      <td>-0.353813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46479</th>\n",
       "      <td>0.971362</td>\n",
       "      <td>-0.716448</td>\n",
       "      <td>-0.803047</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.695973</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>2.330176</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>3.056626</td>\n",
       "      <td>-1.030506</td>\n",
       "      <td>-0.598176</td>\n",
       "      <td>-0.504194</td>\n",
       "      <td>-0.462525</td>\n",
       "      <td>-0.168681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115581</th>\n",
       "      <td>-1.029482</td>\n",
       "      <td>-0.095676</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.737192</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>1.436838</td>\n",
       "      <td>-0.423252</td>\n",
       "      <td>-0.808640</td>\n",
       "      <td>-0.08895</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>-0.874557</td>\n",
       "      <td>-0.343833</td>\n",
       "      <td>-0.593247</td>\n",
       "      <td>-0.562138</td>\n",
       "      <td>-0.508090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sex       age    weight    height      HIPX  menopause       HRT  \\\n",
       "149978 -1.029482  0.152632 -1.383228 -1.438686 -0.037838   1.436838 -0.423252   \n",
       "43265   0.971362 -1.957990  0.637841  1.770734 -0.037838  -0.695973 -0.423252   \n",
       "116861  0.971362  1.145866  2.161613  1.498749 -0.037838  -0.695973 -0.423252   \n",
       "46479   0.971362 -0.716448 -0.803047  0.845986 -0.037838  -0.695973 -0.423252   \n",
       "115581 -1.029482 -0.095676  0.274431  0.737192 -0.037838   1.436838 -0.423252   \n",
       "\n",
       "         smoking  ReumatoidArthritis  SecondaryOsteoporsis   Alcohol  \\\n",
       "149978 -0.808640            -0.08895             -0.134216 -0.612333   \n",
       "43265   0.760768            -0.08895             -0.134216  0.104979   \n",
       "116861  0.760768            -0.08895             -0.134216  0.104979   \n",
       "46479   2.330176            -0.08895             -0.134216  3.056626   \n",
       "115581 -0.808640            -0.08895             -0.134216  0.397031   \n",
       "\n",
       "        VitaminD   calcium  dose_walk  dose_moderate  dose_vigorous  \\\n",
       "149978 -0.141958  0.115530  -0.259297      -0.462525      -0.538945   \n",
       "43265   1.276093  0.113305  -0.637774      -0.611945       0.201583   \n",
       "116861 -0.504631 -0.366965  -0.493062       0.583416      -0.353813   \n",
       "46479  -1.030506 -0.598176  -0.504194      -0.462525      -0.168681   \n",
       "115581 -0.874557 -0.343833  -0.593247      -0.562138      -0.508090   \n",
       "\n",
       "        real_class  predicted_class  \n",
       "149978           0                0  \n",
       "43265            0                0  \n",
       "116861           0                0  \n",
       "46479            0                1  \n",
       "115581           0                0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_df_complete = mod_df[(mod_df['real_class'] == 0) & ( mod_df['predicted_class']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erennio/anaconda2/envs/Python36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8771, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df_complete['Class'] = mod_df['real_class']\n",
    "mod_df_complete = mod_df_complete.drop(['real_class','predicted_class'],axis=1)\n",
    "mod_df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153884, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_patients = pd.read_csv('../Data/standardized_patients.csv', index_col=0)\n",
    "std_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index in mod_df_complete.index.values:\n",
    "    feature_to_check = std_patients.loc[index].round(10) == mod_df_complete.loc[index].round(10)\n",
    "    for check in feature_to_check:\n",
    "        if not check:\n",
    "            print(index, feature_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in mod_df_complete.index.values:\n",
    "    equals = True\n",
    "    patient = std_patients.loc[index].round(10) == mod_df_complete.loc[index].round(10)\n",
    "    for feature in patient:\n",
    "        if not feature:\n",
    "            equals = False\n",
    "            print(std_patients.loc[index].round(10) == giorgiONE.loc[index].round(10), index)\n",
    "    if equals:\n",
    "        std_patients.loc[index,'Class'] = 1        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8771,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_patients.loc[mod_df_complete.index.values,'Class'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_patients.to_csv('../Data/new_std_patients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NeuralNetwork - First Run.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlp, 'NeuralNetwork - First Run.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
